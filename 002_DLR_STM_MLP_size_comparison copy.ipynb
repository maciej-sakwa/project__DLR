{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading - the 'clean' data has datetime index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(r\"C:\\Users\\macie\\OneDrive\\Pulpit\\Fellowship\\999_OTHER\\DP_paper\\Line_Test1.csv\")\n",
    "df_temp.index = df_temp.apply(lambda row: datetime(year=int(row.Year), month=int(row.Month), day=int(row.Day), hour=int(row.Hour), minute=int(row.Minute)), axis=1)\n",
    "df_temp.rename(columns={'TEMP_LINE_SM1':'temp'}, inplace=True)\n",
    "df_temp.ffill(inplace=True)\n",
    "df_temp_resampled = df_temp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data standardization - std. scaling. We pick only the temperature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(df_temp_resampled.temp)\n",
    "\n",
    "data_mean = df_data.mean()\n",
    "data_std = df_data.std()\n",
    "df_data = (df_data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splits - train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = len(df_data)\n",
    "\n",
    "df_train = df_data[:int(0.7*len_data)]\n",
    "df_val = df_data[int(0.7*len_data):int(0.9*len_data)]\n",
    "df_test = df_data[int(0.9*len_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-03 19:15:00</th>\n",
       "      <td>-0.508727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 19:20:00</th>\n",
       "      <td>-0.451950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 19:25:00</th>\n",
       "      <td>-0.427617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 19:30:00</th>\n",
       "      <td>-0.439784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 19:35:00</th>\n",
       "      <td>-0.456006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 23:35:00</th>\n",
       "      <td>0.156378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 23:40:00</th>\n",
       "      <td>0.136100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 23:45:00</th>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 23:50:00</th>\n",
       "      <td>0.095545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 23:55:00</th>\n",
       "      <td>0.091489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         temp\n",
       "2019-01-03 19:15:00 -0.508727\n",
       "2019-01-03 19:20:00 -0.451950\n",
       "2019-01-03 19:25:00 -0.427617\n",
       "2019-01-03 19:30:00 -0.439784\n",
       "2019-01-03 19:35:00 -0.456006\n",
       "...                       ...\n",
       "2019-01-06 23:35:00  0.156378\n",
       "2019-01-06 23:40:00  0.136100\n",
       "2019-01-06 23:45:00  0.099600\n",
       "2019-01-06 23:50:00  0.095545\n",
       "2019-01-06 23:55:00  0.091489\n",
       "\n",
       "[921 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time window genrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window generator -> to be fed into the model. Sets up the time windows for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeWindowGenerator():\n",
    "\n",
    "    def __init__(self, input_width, output_width=1, output_offset=1, df_train = df_train, df_val=df_val, df_test=df_test, column_name = ['temp']):\n",
    "\n",
    "        # define the raw datasets\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.df_test = df_test\n",
    "\n",
    "        # Window parameters\n",
    "        self.input_width = input_width\n",
    "        self.output_width = output_width\n",
    "        self.offset = output_offset\n",
    "        self.total_size = self.input_width + self.offset\n",
    "        \n",
    "        # Define the indices\n",
    "        self.input_indices = np.arange(0, self.input_width)\n",
    "        self.output_indices = np.arange(self.total_size - self.output_width, self.total_size)\n",
    "        \n",
    "    # model representation when called\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.output_indices}'])\n",
    "    \n",
    "\n",
    "    def slice(self, batches):\n",
    "        # For training probably many batches, for test and deployment: one at a time\n",
    "        if len(np.shape(batches)) == 3:\n",
    "            inputs = batches[:, slice(0, self.input_width)]\n",
    "            output = batches[:, slice(self.total_size - self.output_width, self.total_size)]\n",
    "\n",
    "        else:\n",
    "            inputs = batches[slice(0, self.input_width)]\n",
    "            output = batches[slice(self.total_size - self.output_width, self.total_size)]\n",
    "\n",
    "        # Set shape for the tf dataset - works only if a tf.Dataset object is fed  \n",
    "        # e.g., a timeseries_dataset_from_array object\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        output.set_shape([None, self.output_width, None])\n",
    "\n",
    "        return inputs, output\n",
    "    \n",
    "    def compile_dataset(self, data, opt_shuffle=True):\n",
    "        # Convert to numpy float32 - for the keras object\n",
    "        data_array = np.array(data, dtype='float32')\n",
    "        \n",
    "        keras_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data = data_array,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=opt_shuffle,\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        keras_dataset = keras_dataset.map(self.slice)\n",
    "\n",
    "        return keras_dataset\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.compile_dataset(self.df_train)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.compile_dataset(self.df_val)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.compile_dataset(self.df_test, opt_shuffle=False)\n",
    "    \n",
    "    @property\n",
    "    def example(self):\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._example = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_trainer(model, model_name, window_generator, max_epochs):\n",
    "  cb_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "  # cb_checkpointing = tf.keras.callbacks.ModelCheckpoint(r'models/line_temp_model_{}_10_mins.hdf5'.format(model_name), monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, clipvalue=1.0),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window_generator.train, epochs=max_epochs,\n",
    "                      validation_data=window_generator.val,\n",
    "                      callbacks=[cb_early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistance model - for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_1 = TimeWindowGenerator(input_width=1, df_train=df_train, df_val=df_val, df_test=df_test, output_offset=3)\n",
    "window_6 = TimeWindowGenerator(input_width=6, df_train=df_train, df_val=df_val, df_test=df_test, output_offset=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 9\n",
       "Input indices: [0 1 2 3 4 5]\n",
       "Label indices: [8]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_05 = tf.keras.Sequential([\n",
    "    # Flatten\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # Reshape into output\n",
    "    tf.keras.layers.Reshape([-1, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_10 = tf.keras.Sequential([\n",
    "    # Flatten\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # Reshape into output\n",
    "    tf.keras.layers.Reshape([-1, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_20 = tf.keras.Sequential([\n",
    "    # Flatten\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # Reshape into output\n",
    "    tf.keras.layers.Reshape([-1, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_05b = tf.keras.Sequential([\n",
    "    # Flatten\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # Reshape into output\n",
    "    tf.keras.layers.Reshape([-1, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_10b = tf.keras.Sequential([\n",
    "    # Flatten\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # Reshape into output\n",
    "    tf.keras.layers.Reshape([-1, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_20b = tf.keras.Sequential([\n",
    "    # Flatten\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # Reshape into output\n",
    "    tf.keras.layers.Reshape([-1, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.0527 - mean_absolute_error: 0.1349 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n"
     ]
    }
   ],
   "source": [
    "persistance_model = Baseline(label_index=None)\n",
    "history_persitance = tiny_trainer(model=persistance_model, model_name='persistence', window_generator=window_1, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.8595 - mean_absolute_error: 0.6581 - val_loss: 1.2185 - val_mean_absolute_error: 0.8013\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.6368 - mean_absolute_error: 0.5606 - val_loss: 0.9112 - val_mean_absolute_error: 0.6822\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4733 - mean_absolute_error: 0.4697 - val_loss: 0.6168 - val_mean_absolute_error: 0.5497\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.2914 - mean_absolute_error: 0.3612 - val_loss: 0.3489 - val_mean_absolute_error: 0.4083\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.1818 - mean_absolute_error: 0.2817 - val_loss: 0.2032 - val_mean_absolute_error: 0.3115\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.1272 - mean_absolute_error: 0.2350 - val_loss: 0.1275 - val_mean_absolute_error: 0.2500\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.1029 - mean_absolute_error: 0.2111 - val_loss: 0.0929 - val_mean_absolute_error: 0.2166\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0928 - mean_absolute_error: 0.1995 - val_loss: 0.0774 - val_mean_absolute_error: 0.1995\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0882 - mean_absolute_error: 0.1932 - val_loss: 0.0699 - val_mean_absolute_error: 0.1903\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0854 - mean_absolute_error: 0.1891 - val_loss: 0.0658 - val_mean_absolute_error: 0.1845\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0832 - mean_absolute_error: 0.1857 - val_loss: 0.0633 - val_mean_absolute_error: 0.1803\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0815 - mean_absolute_error: 0.1832 - val_loss: 0.0613 - val_mean_absolute_error: 0.1768\n",
      "Epoch 13/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0800 - mean_absolute_error: 0.1809 - val_loss: 0.0596 - val_mean_absolute_error: 0.1738\n",
      "Epoch 14/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0785 - mean_absolute_error: 0.1790 - val_loss: 0.0582 - val_mean_absolute_error: 0.1712\n",
      "Epoch 15/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0769 - mean_absolute_error: 0.1767 - val_loss: 0.0568 - val_mean_absolute_error: 0.1687\n",
      "Epoch 16/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0748 - mean_absolute_error: 0.1741 - val_loss: 0.0553 - val_mean_absolute_error: 0.1654\n",
      "Epoch 17/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0726 - mean_absolute_error: 0.1712 - val_loss: 0.0535 - val_mean_absolute_error: 0.1618\n",
      "Epoch 18/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0709 - mean_absolute_error: 0.1690 - val_loss: 0.0524 - val_mean_absolute_error: 0.1597\n",
      "Epoch 19/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0695 - mean_absolute_error: 0.1671 - val_loss: 0.0513 - val_mean_absolute_error: 0.1581\n",
      "Epoch 20/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0685 - mean_absolute_error: 0.1655 - val_loss: 0.0504 - val_mean_absolute_error: 0.1566\n",
      "Epoch 21/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0676 - mean_absolute_error: 0.1641 - val_loss: 0.0495 - val_mean_absolute_error: 0.1553\n",
      "Epoch 22/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0667 - mean_absolute_error: 0.1629 - val_loss: 0.0489 - val_mean_absolute_error: 0.1544\n",
      "Epoch 23/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0658 - mean_absolute_error: 0.1617 - val_loss: 0.0482 - val_mean_absolute_error: 0.1534\n",
      "Epoch 24/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0651 - mean_absolute_error: 0.1606 - val_loss: 0.0474 - val_mean_absolute_error: 0.1522\n",
      "Epoch 25/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0643 - mean_absolute_error: 0.1596 - val_loss: 0.0468 - val_mean_absolute_error: 0.1513\n",
      "Epoch 26/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0636 - mean_absolute_error: 0.1586 - val_loss: 0.0463 - val_mean_absolute_error: 0.1506\n",
      "Epoch 27/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0629 - mean_absolute_error: 0.1576 - val_loss: 0.0458 - val_mean_absolute_error: 0.1497\n",
      "Epoch 28/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0624 - mean_absolute_error: 0.1568 - val_loss: 0.0453 - val_mean_absolute_error: 0.1490\n",
      "Epoch 29/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0618 - mean_absolute_error: 0.1560 - val_loss: 0.0448 - val_mean_absolute_error: 0.1482\n",
      "Epoch 30/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0613 - mean_absolute_error: 0.1553 - val_loss: 0.0444 - val_mean_absolute_error: 0.1475\n",
      "Epoch 31/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0608 - mean_absolute_error: 0.1545 - val_loss: 0.0440 - val_mean_absolute_error: 0.1468\n",
      "Epoch 32/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0603 - mean_absolute_error: 0.1536 - val_loss: 0.0438 - val_mean_absolute_error: 0.1463\n",
      "Epoch 33/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0597 - mean_absolute_error: 0.1527 - val_loss: 0.0436 - val_mean_absolute_error: 0.1457\n",
      "Epoch 34/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0591 - mean_absolute_error: 0.1517 - val_loss: 0.0430 - val_mean_absolute_error: 0.1448\n",
      "Epoch 35/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0585 - mean_absolute_error: 0.1506 - val_loss: 0.0426 - val_mean_absolute_error: 0.1439\n",
      "Epoch 36/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0581 - mean_absolute_error: 0.1498 - val_loss: 0.0419 - val_mean_absolute_error: 0.1431\n",
      "Epoch 37/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0577 - mean_absolute_error: 0.1494 - val_loss: 0.0415 - val_mean_absolute_error: 0.1423\n",
      "Epoch 38/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0573 - mean_absolute_error: 0.1484 - val_loss: 0.0413 - val_mean_absolute_error: 0.1416\n",
      "Epoch 39/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0570 - mean_absolute_error: 0.1478 - val_loss: 0.0409 - val_mean_absolute_error: 0.1410\n",
      "Epoch 40/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0567 - mean_absolute_error: 0.1473 - val_loss: 0.0406 - val_mean_absolute_error: 0.1405\n",
      "Epoch 41/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0564 - mean_absolute_error: 0.1467 - val_loss: 0.0404 - val_mean_absolute_error: 0.1401\n",
      "Epoch 42/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0562 - mean_absolute_error: 0.1464 - val_loss: 0.0402 - val_mean_absolute_error: 0.1397\n",
      "Epoch 43/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0560 - mean_absolute_error: 0.1460 - val_loss: 0.0398 - val_mean_absolute_error: 0.1392\n",
      "Epoch 44/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0558 - mean_absolute_error: 0.1455 - val_loss: 0.0397 - val_mean_absolute_error: 0.1388\n",
      "Epoch 45/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0556 - mean_absolute_error: 0.1453 - val_loss: 0.0396 - val_mean_absolute_error: 0.1385\n",
      "Epoch 46/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0554 - mean_absolute_error: 0.1447 - val_loss: 0.0394 - val_mean_absolute_error: 0.1381\n",
      "Epoch 47/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0552 - mean_absolute_error: 0.1445 - val_loss: 0.0392 - val_mean_absolute_error: 0.1377\n",
      "Epoch 48/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0550 - mean_absolute_error: 0.1441 - val_loss: 0.0392 - val_mean_absolute_error: 0.1374\n",
      "Epoch 49/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0549 - mean_absolute_error: 0.1439 - val_loss: 0.0389 - val_mean_absolute_error: 0.1371\n",
      "Epoch 50/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0547 - mean_absolute_error: 0.1436 - val_loss: 0.0388 - val_mean_absolute_error: 0.1369\n",
      "Epoch 51/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0546 - mean_absolute_error: 0.1435 - val_loss: 0.0389 - val_mean_absolute_error: 0.1366\n",
      "Epoch 52/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0545 - mean_absolute_error: 0.1431 - val_loss: 0.0387 - val_mean_absolute_error: 0.1363\n",
      "Epoch 53/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0543 - mean_absolute_error: 0.1429 - val_loss: 0.0385 - val_mean_absolute_error: 0.1360\n",
      "Epoch 54/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0541 - mean_absolute_error: 0.1426 - val_loss: 0.0385 - val_mean_absolute_error: 0.1357\n",
      "Epoch 55/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0540 - mean_absolute_error: 0.1423 - val_loss: 0.0384 - val_mean_absolute_error: 0.1354\n",
      "Epoch 56/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0539 - mean_absolute_error: 0.1421 - val_loss: 0.0384 - val_mean_absolute_error: 0.1352\n",
      "Epoch 57/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0538 - mean_absolute_error: 0.1418 - val_loss: 0.0382 - val_mean_absolute_error: 0.1349\n",
      "Epoch 58/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0537 - mean_absolute_error: 0.1418 - val_loss: 0.0381 - val_mean_absolute_error: 0.1346\n",
      "Epoch 59/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0536 - mean_absolute_error: 0.1414 - val_loss: 0.0380 - val_mean_absolute_error: 0.1345\n",
      "Epoch 60/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1414 - val_loss: 0.0380 - val_mean_absolute_error: 0.1344\n",
      "Epoch 61/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1412 - val_loss: 0.0380 - val_mean_absolute_error: 0.1341\n",
      "Epoch 62/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0533 - mean_absolute_error: 0.1410 - val_loss: 0.0379 - val_mean_absolute_error: 0.1339\n",
      "Epoch 63/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0532 - mean_absolute_error: 0.1411 - val_loss: 0.0378 - val_mean_absolute_error: 0.1337\n",
      "Epoch 64/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0531 - mean_absolute_error: 0.1406 - val_loss: 0.0377 - val_mean_absolute_error: 0.1335\n",
      "Epoch 65/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1406 - val_loss: 0.0378 - val_mean_absolute_error: 0.1333\n",
      "Epoch 66/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1405 - val_loss: 0.0376 - val_mean_absolute_error: 0.1332\n",
      "Epoch 67/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0529 - mean_absolute_error: 0.1403 - val_loss: 0.0377 - val_mean_absolute_error: 0.1331\n",
      "Epoch 68/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0528 - mean_absolute_error: 0.1402 - val_loss: 0.0376 - val_mean_absolute_error: 0.1328\n",
      "Epoch 69/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1400 - val_loss: 0.0374 - val_mean_absolute_error: 0.1327\n",
      "Epoch 70/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0526 - mean_absolute_error: 0.1400 - val_loss: 0.0374 - val_mean_absolute_error: 0.1326\n",
      "Epoch 71/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0525 - mean_absolute_error: 0.1399 - val_loss: 0.0372 - val_mean_absolute_error: 0.1323\n",
      "Epoch 72/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0525 - mean_absolute_error: 0.1396 - val_loss: 0.0373 - val_mean_absolute_error: 0.1323\n",
      "Epoch 73/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1399 - val_loss: 0.0373 - val_mean_absolute_error: 0.1321\n",
      "Epoch 74/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1394 - val_loss: 0.0372 - val_mean_absolute_error: 0.1321\n",
      "Epoch 75/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0523 - mean_absolute_error: 0.1394 - val_loss: 0.0372 - val_mean_absolute_error: 0.1321\n",
      "Epoch 76/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0522 - mean_absolute_error: 0.1393 - val_loss: 0.0372 - val_mean_absolute_error: 0.1319\n",
      "Epoch 77/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1391 - val_loss: 0.0371 - val_mean_absolute_error: 0.1317\n",
      "Epoch 78/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1391 - val_loss: 0.0371 - val_mean_absolute_error: 0.1316\n",
      "Epoch 79/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0521 - mean_absolute_error: 0.1390 - val_loss: 0.0369 - val_mean_absolute_error: 0.1313\n",
      "Epoch 80/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1388 - val_loss: 0.0369 - val_mean_absolute_error: 0.1313\n",
      "Epoch 81/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1387 - val_loss: 0.0369 - val_mean_absolute_error: 0.1312\n",
      "Epoch 82/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1385 - val_loss: 0.0368 - val_mean_absolute_error: 0.1311\n",
      "Epoch 83/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1385 - val_loss: 0.0369 - val_mean_absolute_error: 0.1311\n",
      "Epoch 84/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0518 - mean_absolute_error: 0.1384 - val_loss: 0.0369 - val_mean_absolute_error: 0.1310\n",
      "Epoch 85/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0518 - mean_absolute_error: 0.1383 - val_loss: 0.0368 - val_mean_absolute_error: 0.1308\n",
      "Epoch 86/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0517 - mean_absolute_error: 0.1383 - val_loss: 0.0367 - val_mean_absolute_error: 0.1307\n",
      "Epoch 87/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0517 - mean_absolute_error: 0.1381 - val_loss: 0.0367 - val_mean_absolute_error: 0.1307\n",
      "Epoch 88/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0517 - mean_absolute_error: 0.1381 - val_loss: 0.0367 - val_mean_absolute_error: 0.1306\n",
      "Epoch 89/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1380 - val_loss: 0.0368 - val_mean_absolute_error: 0.1307\n",
      "Epoch 90/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1380 - val_loss: 0.0366 - val_mean_absolute_error: 0.1303\n",
      "Epoch 91/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0515 - mean_absolute_error: 0.1378 - val_loss: 0.0365 - val_mean_absolute_error: 0.1304\n",
      "Epoch 92/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0515 - mean_absolute_error: 0.1379 - val_loss: 0.0366 - val_mean_absolute_error: 0.1303\n",
      "Epoch 93/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0515 - mean_absolute_error: 0.1377 - val_loss: 0.0366 - val_mean_absolute_error: 0.1302\n",
      "Epoch 94/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1376 - val_loss: 0.0365 - val_mean_absolute_error: 0.1303\n",
      "Epoch 95/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1376 - val_loss: 0.0366 - val_mean_absolute_error: 0.1302\n",
      "Epoch 96/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0514 - mean_absolute_error: 0.1378 - val_loss: 0.0365 - val_mean_absolute_error: 0.1301\n"
     ]
    }
   ],
   "source": [
    "history_mlp = tiny_trainer(model=mlp_model_05, model_name='mlp_05', window_generator=window_6, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.4908 - mean_absolute_error: 0.5600 - val_loss: 0.3518 - val_mean_absolute_error: 0.4766\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.3370 - mean_absolute_error: 0.4497 - val_loss: 0.2372 - val_mean_absolute_error: 0.3791\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.2414 - mean_absolute_error: 0.3767 - val_loss: 0.1607 - val_mean_absolute_error: 0.3098\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.1678 - mean_absolute_error: 0.3100 - val_loss: 0.1079 - val_mean_absolute_error: 0.2503\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.1205 - mean_absolute_error: 0.2544 - val_loss: 0.0796 - val_mean_absolute_error: 0.2080\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0987 - mean_absolute_error: 0.2196 - val_loss: 0.0686 - val_mean_absolute_error: 0.1863\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0901 - mean_absolute_error: 0.2009 - val_loss: 0.0642 - val_mean_absolute_error: 0.1770\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0857 - mean_absolute_error: 0.1911 - val_loss: 0.0613 - val_mean_absolute_error: 0.1719\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.1844 - val_loss: 0.0589 - val_mean_absolute_error: 0.1677\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0796 - mean_absolute_error: 0.1789 - val_loss: 0.0568 - val_mean_absolute_error: 0.1639\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0772 - mean_absolute_error: 0.1741 - val_loss: 0.0551 - val_mean_absolute_error: 0.1609\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0753 - mean_absolute_error: 0.1704 - val_loss: 0.0538 - val_mean_absolute_error: 0.1587\n",
      "Epoch 13/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0738 - mean_absolute_error: 0.1677 - val_loss: 0.0527 - val_mean_absolute_error: 0.1568\n",
      "Epoch 14/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.1654 - val_loss: 0.0519 - val_mean_absolute_error: 0.1553\n",
      "Epoch 15/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0713 - mean_absolute_error: 0.1635 - val_loss: 0.0508 - val_mean_absolute_error: 0.1537\n",
      "Epoch 16/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0703 - mean_absolute_error: 0.1619 - val_loss: 0.0503 - val_mean_absolute_error: 0.1526\n",
      "Epoch 17/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0693 - mean_absolute_error: 0.1603 - val_loss: 0.0495 - val_mean_absolute_error: 0.1515\n",
      "Epoch 18/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0684 - mean_absolute_error: 0.1590 - val_loss: 0.0488 - val_mean_absolute_error: 0.1502\n",
      "Epoch 19/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0676 - mean_absolute_error: 0.1578 - val_loss: 0.0483 - val_mean_absolute_error: 0.1492\n",
      "Epoch 20/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0669 - mean_absolute_error: 0.1566 - val_loss: 0.0478 - val_mean_absolute_error: 0.1482\n",
      "Epoch 21/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0661 - mean_absolute_error: 0.1558 - val_loss: 0.0473 - val_mean_absolute_error: 0.1474\n",
      "Epoch 22/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0655 - mean_absolute_error: 0.1548 - val_loss: 0.0467 - val_mean_absolute_error: 0.1462\n",
      "Epoch 23/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0648 - mean_absolute_error: 0.1538 - val_loss: 0.0465 - val_mean_absolute_error: 0.1457\n",
      "Epoch 24/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0642 - mean_absolute_error: 0.1531 - val_loss: 0.0461 - val_mean_absolute_error: 0.1449\n",
      "Epoch 25/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0637 - mean_absolute_error: 0.1524 - val_loss: 0.0458 - val_mean_absolute_error: 0.1442\n",
      "Epoch 26/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0632 - mean_absolute_error: 0.1517 - val_loss: 0.0454 - val_mean_absolute_error: 0.1435\n",
      "Epoch 27/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0627 - mean_absolute_error: 0.1513 - val_loss: 0.0451 - val_mean_absolute_error: 0.1428\n",
      "Epoch 28/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0622 - mean_absolute_error: 0.1504 - val_loss: 0.0449 - val_mean_absolute_error: 0.1423\n",
      "Epoch 29/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0617 - mean_absolute_error: 0.1499 - val_loss: 0.0446 - val_mean_absolute_error: 0.1418\n",
      "Epoch 30/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0613 - mean_absolute_error: 0.1493 - val_loss: 0.0442 - val_mean_absolute_error: 0.1411\n",
      "Epoch 31/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0609 - mean_absolute_error: 0.1488 - val_loss: 0.0439 - val_mean_absolute_error: 0.1407\n",
      "Epoch 32/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0605 - mean_absolute_error: 0.1484 - val_loss: 0.0438 - val_mean_absolute_error: 0.1403\n",
      "Epoch 33/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0602 - mean_absolute_error: 0.1480 - val_loss: 0.0435 - val_mean_absolute_error: 0.1399\n",
      "Epoch 34/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0599 - mean_absolute_error: 0.1476 - val_loss: 0.0433 - val_mean_absolute_error: 0.1397\n",
      "Epoch 35/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0596 - mean_absolute_error: 0.1473 - val_loss: 0.0432 - val_mean_absolute_error: 0.1393\n",
      "Epoch 36/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0593 - mean_absolute_error: 0.1469 - val_loss: 0.0429 - val_mean_absolute_error: 0.1389\n",
      "Epoch 37/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0591 - mean_absolute_error: 0.1466 - val_loss: 0.0426 - val_mean_absolute_error: 0.1386\n",
      "Epoch 38/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0589 - mean_absolute_error: 0.1464 - val_loss: 0.0427 - val_mean_absolute_error: 0.1388\n",
      "Epoch 39/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0586 - mean_absolute_error: 0.1460 - val_loss: 0.0423 - val_mean_absolute_error: 0.1380\n",
      "Epoch 40/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0584 - mean_absolute_error: 0.1459 - val_loss: 0.0423 - val_mean_absolute_error: 0.1380\n",
      "Epoch 41/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0582 - mean_absolute_error: 0.1456 - val_loss: 0.0422 - val_mean_absolute_error: 0.1379\n",
      "Epoch 42/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0580 - mean_absolute_error: 0.1453 - val_loss: 0.0419 - val_mean_absolute_error: 0.1375\n",
      "Epoch 43/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0579 - mean_absolute_error: 0.1451 - val_loss: 0.0417 - val_mean_absolute_error: 0.1372\n",
      "Epoch 44/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0577 - mean_absolute_error: 0.1449 - val_loss: 0.0419 - val_mean_absolute_error: 0.1375\n",
      "Epoch 45/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0575 - mean_absolute_error: 0.1448 - val_loss: 0.0416 - val_mean_absolute_error: 0.1370\n",
      "Epoch 46/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0573 - mean_absolute_error: 0.1444 - val_loss: 0.0416 - val_mean_absolute_error: 0.1369\n",
      "Epoch 47/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0572 - mean_absolute_error: 0.1445 - val_loss: 0.0413 - val_mean_absolute_error: 0.1368\n",
      "Epoch 48/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0570 - mean_absolute_error: 0.1442 - val_loss: 0.0414 - val_mean_absolute_error: 0.1368\n",
      "Epoch 49/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0569 - mean_absolute_error: 0.1439 - val_loss: 0.0412 - val_mean_absolute_error: 0.1365\n",
      "Epoch 50/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0567 - mean_absolute_error: 0.1437 - val_loss: 0.0413 - val_mean_absolute_error: 0.1364\n",
      "Epoch 51/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0566 - mean_absolute_error: 0.1436 - val_loss: 0.0411 - val_mean_absolute_error: 0.1361\n",
      "Epoch 52/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0564 - mean_absolute_error: 0.1434 - val_loss: 0.0411 - val_mean_absolute_error: 0.1362\n",
      "Epoch 53/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0563 - mean_absolute_error: 0.1433 - val_loss: 0.0410 - val_mean_absolute_error: 0.1362\n",
      "Epoch 54/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0562 - mean_absolute_error: 0.1433 - val_loss: 0.0408 - val_mean_absolute_error: 0.1359\n",
      "Epoch 55/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0561 - mean_absolute_error: 0.1430 - val_loss: 0.0407 - val_mean_absolute_error: 0.1358\n",
      "Epoch 56/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0560 - mean_absolute_error: 0.1427 - val_loss: 0.0406 - val_mean_absolute_error: 0.1356\n",
      "Epoch 57/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0559 - mean_absolute_error: 0.1427 - val_loss: 0.0407 - val_mean_absolute_error: 0.1356\n",
      "Epoch 58/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0557 - mean_absolute_error: 0.1424 - val_loss: 0.0405 - val_mean_absolute_error: 0.1354\n",
      "Epoch 59/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0556 - mean_absolute_error: 0.1425 - val_loss: 0.0404 - val_mean_absolute_error: 0.1353\n",
      "Epoch 60/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0555 - mean_absolute_error: 0.1422 - val_loss: 0.0403 - val_mean_absolute_error: 0.1352\n",
      "Epoch 61/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0554 - mean_absolute_error: 0.1420 - val_loss: 0.0404 - val_mean_absolute_error: 0.1352\n",
      "Epoch 62/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0553 - mean_absolute_error: 0.1420 - val_loss: 0.0402 - val_mean_absolute_error: 0.1350\n",
      "Epoch 63/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0551 - mean_absolute_error: 0.1417 - val_loss: 0.0400 - val_mean_absolute_error: 0.1346\n",
      "Epoch 64/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0550 - mean_absolute_error: 0.1416 - val_loss: 0.0400 - val_mean_absolute_error: 0.1347\n",
      "Epoch 65/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0549 - mean_absolute_error: 0.1415 - val_loss: 0.0399 - val_mean_absolute_error: 0.1343\n",
      "Epoch 66/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0548 - mean_absolute_error: 0.1414 - val_loss: 0.0399 - val_mean_absolute_error: 0.1345\n",
      "Epoch 67/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0547 - mean_absolute_error: 0.1412 - val_loss: 0.0399 - val_mean_absolute_error: 0.1342\n",
      "Epoch 68/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0546 - mean_absolute_error: 0.1413 - val_loss: 0.0398 - val_mean_absolute_error: 0.1344\n",
      "Epoch 69/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0545 - mean_absolute_error: 0.1410 - val_loss: 0.0396 - val_mean_absolute_error: 0.1339\n",
      "Epoch 70/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0544 - mean_absolute_error: 0.1410 - val_loss: 0.0398 - val_mean_absolute_error: 0.1343\n",
      "Epoch 71/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0543 - mean_absolute_error: 0.1408 - val_loss: 0.0395 - val_mean_absolute_error: 0.1337\n",
      "Epoch 72/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0542 - mean_absolute_error: 0.1407 - val_loss: 0.0395 - val_mean_absolute_error: 0.1339\n",
      "Epoch 73/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0541 - mean_absolute_error: 0.1407 - val_loss: 0.0394 - val_mean_absolute_error: 0.1338\n",
      "Epoch 74/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0540 - mean_absolute_error: 0.1404 - val_loss: 0.0395 - val_mean_absolute_error: 0.1337\n",
      "Epoch 75/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0539 - mean_absolute_error: 0.1404 - val_loss: 0.0392 - val_mean_absolute_error: 0.1335\n",
      "Epoch 76/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0539 - mean_absolute_error: 0.1402 - val_loss: 0.0393 - val_mean_absolute_error: 0.1337\n",
      "Epoch 77/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0538 - mean_absolute_error: 0.1401 - val_loss: 0.0393 - val_mean_absolute_error: 0.1334\n",
      "Epoch 78/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0537 - mean_absolute_error: 0.1400 - val_loss: 0.0393 - val_mean_absolute_error: 0.1336\n",
      "Epoch 79/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0536 - mean_absolute_error: 0.1399 - val_loss: 0.0390 - val_mean_absolute_error: 0.1331\n",
      "Epoch 80/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0535 - mean_absolute_error: 0.1397 - val_loss: 0.0391 - val_mean_absolute_error: 0.1332\n",
      "Epoch 81/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1396 - val_loss: 0.0390 - val_mean_absolute_error: 0.1332\n",
      "Epoch 82/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1396 - val_loss: 0.0391 - val_mean_absolute_error: 0.1333\n",
      "Epoch 83/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0532 - mean_absolute_error: 0.1394 - val_loss: 0.0390 - val_mean_absolute_error: 0.1329\n",
      "Epoch 84/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0532 - mean_absolute_error: 0.1393 - val_loss: 0.0388 - val_mean_absolute_error: 0.1327\n",
      "Epoch 85/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0531 - mean_absolute_error: 0.1394 - val_loss: 0.0387 - val_mean_absolute_error: 0.1327\n",
      "Epoch 86/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1392 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 87/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0530 - mean_absolute_error: 0.1391 - val_loss: 0.0387 - val_mean_absolute_error: 0.1325\n",
      "Epoch 88/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0529 - mean_absolute_error: 0.1390 - val_loss: 0.0387 - val_mean_absolute_error: 0.1325\n",
      "Epoch 89/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1388 - val_loss: 0.0387 - val_mean_absolute_error: 0.1326\n",
      "Epoch 90/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0527 - mean_absolute_error: 0.1387 - val_loss: 0.0386 - val_mean_absolute_error: 0.1324\n",
      "Epoch 91/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1387 - val_loss: 0.0386 - val_mean_absolute_error: 0.1322\n",
      "Epoch 92/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0526 - mean_absolute_error: 0.1385 - val_loss: 0.0385 - val_mean_absolute_error: 0.1321\n",
      "Epoch 93/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0526 - mean_absolute_error: 0.1386 - val_loss: 0.0384 - val_mean_absolute_error: 0.1320\n",
      "Epoch 94/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0525 - mean_absolute_error: 0.1384 - val_loss: 0.0385 - val_mean_absolute_error: 0.1320\n",
      "Epoch 95/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1384 - val_loss: 0.0384 - val_mean_absolute_error: 0.1319\n",
      "Epoch 96/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1382 - val_loss: 0.0383 - val_mean_absolute_error: 0.1320\n",
      "Epoch 97/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0523 - mean_absolute_error: 0.1383 - val_loss: 0.0383 - val_mean_absolute_error: 0.1316\n",
      "Epoch 98/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1380 - val_loss: 0.0382 - val_mean_absolute_error: 0.1318\n",
      "Epoch 99/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1379 - val_loss: 0.0382 - val_mean_absolute_error: 0.1317\n",
      "Epoch 100/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0521 - mean_absolute_error: 0.1379 - val_loss: 0.0381 - val_mean_absolute_error: 0.1315\n",
      "Epoch 101/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0521 - mean_absolute_error: 0.1379 - val_loss: 0.0383 - val_mean_absolute_error: 0.1319\n",
      "Epoch 102/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1378 - val_loss: 0.0383 - val_mean_absolute_error: 0.1316\n",
      "Epoch 103/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1376 - val_loss: 0.0381 - val_mean_absolute_error: 0.1316\n",
      "Epoch 104/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0519 - mean_absolute_error: 0.1376 - val_loss: 0.0381 - val_mean_absolute_error: 0.1314\n",
      "Epoch 105/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0519 - mean_absolute_error: 0.1375 - val_loss: 0.0382 - val_mean_absolute_error: 0.1313\n",
      "Epoch 106/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0518 - mean_absolute_error: 0.1375 - val_loss: 0.0381 - val_mean_absolute_error: 0.1312\n",
      "Epoch 107/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0517 - mean_absolute_error: 0.1374 - val_loss: 0.0380 - val_mean_absolute_error: 0.1311\n",
      "Epoch 108/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0517 - mean_absolute_error: 0.1373 - val_loss: 0.0379 - val_mean_absolute_error: 0.1312\n",
      "Epoch 109/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1373 - val_loss: 0.0379 - val_mean_absolute_error: 0.1311\n",
      "Epoch 110/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1371 - val_loss: 0.0379 - val_mean_absolute_error: 0.1309\n",
      "Epoch 111/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0515 - mean_absolute_error: 0.1371 - val_loss: 0.0377 - val_mean_absolute_error: 0.1308\n",
      "Epoch 112/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0515 - mean_absolute_error: 0.1370 - val_loss: 0.0377 - val_mean_absolute_error: 0.1308\n",
      "Epoch 113/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1370 - val_loss: 0.0377 - val_mean_absolute_error: 0.1310\n",
      "Epoch 114/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1369 - val_loss: 0.0376 - val_mean_absolute_error: 0.1307\n",
      "Epoch 115/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0513 - mean_absolute_error: 0.1367 - val_loss: 0.0377 - val_mean_absolute_error: 0.1307\n",
      "Epoch 116/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0513 - mean_absolute_error: 0.1367 - val_loss: 0.0377 - val_mean_absolute_error: 0.1308\n",
      "Epoch 117/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0512 - mean_absolute_error: 0.1368 - val_loss: 0.0376 - val_mean_absolute_error: 0.1307\n",
      "Epoch 118/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0512 - mean_absolute_error: 0.1368 - val_loss: 0.0376 - val_mean_absolute_error: 0.1307\n",
      "Epoch 119/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0512 - mean_absolute_error: 0.1367 - val_loss: 0.0375 - val_mean_absolute_error: 0.1304\n",
      "Epoch 120/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0511 - mean_absolute_error: 0.1365 - val_loss: 0.0376 - val_mean_absolute_error: 0.1308\n",
      "Epoch 121/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0511 - mean_absolute_error: 0.1364 - val_loss: 0.0376 - val_mean_absolute_error: 0.1304\n",
      "Epoch 122/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0511 - mean_absolute_error: 0.1364 - val_loss: 0.0376 - val_mean_absolute_error: 0.1305\n",
      "Epoch 123/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0510 - mean_absolute_error: 0.1364 - val_loss: 0.0375 - val_mean_absolute_error: 0.1304\n",
      "Epoch 124/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0510 - mean_absolute_error: 0.1363 - val_loss: 0.0375 - val_mean_absolute_error: 0.1300\n"
     ]
    }
   ],
   "source": [
    "history_mlp = tiny_trainer(model=mlp_model_10, model_name='mlp_10', window_generator=window_6, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 1.3353 - mean_absolute_error: 0.7430 - val_loss: 1.3357 - val_mean_absolute_error: 0.7596\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4663 - mean_absolute_error: 0.4137 - val_loss: 0.3996 - val_mean_absolute_error: 0.4213\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.1618 - mean_absolute_error: 0.2557 - val_loss: 0.1243 - val_mean_absolute_error: 0.2483\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0928 - mean_absolute_error: 0.1989 - val_loss: 0.0725 - val_mean_absolute_error: 0.1939\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0810 - mean_absolute_error: 0.1838 - val_loss: 0.0617 - val_mean_absolute_error: 0.1785\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0763 - mean_absolute_error: 0.1759 - val_loss: 0.0573 - val_mean_absolute_error: 0.1708\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.1710 - val_loss: 0.0546 - val_mean_absolute_error: 0.1656\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0705 - mean_absolute_error: 0.1669 - val_loss: 0.0523 - val_mean_absolute_error: 0.1609\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0680 - mean_absolute_error: 0.1629 - val_loss: 0.0502 - val_mean_absolute_error: 0.1565\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0657 - mean_absolute_error: 0.1595 - val_loss: 0.0485 - val_mean_absolute_error: 0.1530\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0636 - mean_absolute_error: 0.1561 - val_loss: 0.0469 - val_mean_absolute_error: 0.1488\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0617 - mean_absolute_error: 0.1531 - val_loss: 0.0449 - val_mean_absolute_error: 0.1447\n",
      "Epoch 13/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0602 - mean_absolute_error: 0.1506 - val_loss: 0.0439 - val_mean_absolute_error: 0.1424\n",
      "Epoch 14/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0593 - mean_absolute_error: 0.1489 - val_loss: 0.0431 - val_mean_absolute_error: 0.1404\n",
      "Epoch 15/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0583 - mean_absolute_error: 0.1473 - val_loss: 0.0424 - val_mean_absolute_error: 0.1392\n",
      "Epoch 16/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0575 - mean_absolute_error: 0.1461 - val_loss: 0.0415 - val_mean_absolute_error: 0.1370\n",
      "Epoch 17/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0568 - mean_absolute_error: 0.1448 - val_loss: 0.0413 - val_mean_absolute_error: 0.1363\n",
      "Epoch 18/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0563 - mean_absolute_error: 0.1441 - val_loss: 0.0406 - val_mean_absolute_error: 0.1351\n",
      "Epoch 19/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0559 - mean_absolute_error: 0.1434 - val_loss: 0.0403 - val_mean_absolute_error: 0.1340\n",
      "Epoch 20/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0554 - mean_absolute_error: 0.1426 - val_loss: 0.0400 - val_mean_absolute_error: 0.1333\n",
      "Epoch 21/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0550 - mean_absolute_error: 0.1422 - val_loss: 0.0397 - val_mean_absolute_error: 0.1328\n",
      "Epoch 22/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0546 - mean_absolute_error: 0.1411 - val_loss: 0.0397 - val_mean_absolute_error: 0.1336\n",
      "Epoch 23/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0544 - mean_absolute_error: 0.1409 - val_loss: 0.0394 - val_mean_absolute_error: 0.1318\n",
      "Epoch 24/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0542 - mean_absolute_error: 0.1406 - val_loss: 0.0394 - val_mean_absolute_error: 0.1315\n",
      "Epoch 25/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0541 - mean_absolute_error: 0.1403 - val_loss: 0.0391 - val_mean_absolute_error: 0.1315\n",
      "Epoch 26/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0539 - mean_absolute_error: 0.1402 - val_loss: 0.0394 - val_mean_absolute_error: 0.1314\n",
      "Epoch 27/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0538 - mean_absolute_error: 0.1402 - val_loss: 0.0392 - val_mean_absolute_error: 0.1308\n",
      "Epoch 28/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0537 - mean_absolute_error: 0.1400 - val_loss: 0.0390 - val_mean_absolute_error: 0.1311\n",
      "Epoch 29/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1397 - val_loss: 0.0387 - val_mean_absolute_error: 0.1305\n",
      "Epoch 30/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0533 - mean_absolute_error: 0.1395 - val_loss: 0.0387 - val_mean_absolute_error: 0.1310\n",
      "Epoch 31/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0531 - mean_absolute_error: 0.1394 - val_loss: 0.0390 - val_mean_absolute_error: 0.1307\n",
      "Epoch 32/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1391 - val_loss: 0.0390 - val_mean_absolute_error: 0.1308\n",
      "Epoch 33/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1393 - val_loss: 0.0389 - val_mean_absolute_error: 0.1308\n",
      "Epoch 34/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0526 - mean_absolute_error: 0.1391 - val_loss: 0.0381 - val_mean_absolute_error: 0.1295\n",
      "Epoch 35/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1385 - val_loss: 0.0385 - val_mean_absolute_error: 0.1309\n",
      "Epoch 36/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0523 - mean_absolute_error: 0.1385 - val_loss: 0.0384 - val_mean_absolute_error: 0.1308\n",
      "Epoch 37/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0521 - mean_absolute_error: 0.1383 - val_loss: 0.0387 - val_mean_absolute_error: 0.1310\n",
      "Epoch 38/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1381 - val_loss: 0.0386 - val_mean_absolute_error: 0.1301\n",
      "Epoch 39/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1380 - val_loss: 0.0382 - val_mean_absolute_error: 0.1291\n"
     ]
    }
   ],
   "source": [
    "history_mlp = tiny_trainer(model=mlp_model_20, model_name='mlp_20', window_generator=window_6, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.1590 - mean_absolute_error: 0.2778 - val_loss: 0.1329 - val_mean_absolute_error: 0.2540\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.1105 - mean_absolute_error: 0.2156 - val_loss: 0.0847 - val_mean_absolute_error: 0.2022\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0971 - mean_absolute_error: 0.1961 - val_loss: 0.0720 - val_mean_absolute_error: 0.1867\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0921 - mean_absolute_error: 0.1896 - val_loss: 0.0677 - val_mean_absolute_error: 0.1813\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0883 - mean_absolute_error: 0.1854 - val_loss: 0.0644 - val_mean_absolute_error: 0.1770\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0849 - mean_absolute_error: 0.1819 - val_loss: 0.0620 - val_mean_absolute_error: 0.1738\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0819 - mean_absolute_error: 0.1789 - val_loss: 0.0594 - val_mean_absolute_error: 0.1704\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0792 - mean_absolute_error: 0.1759 - val_loss: 0.0573 - val_mean_absolute_error: 0.1674\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0768 - mean_absolute_error: 0.1733 - val_loss: 0.0554 - val_mean_absolute_error: 0.1647\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0748 - mean_absolute_error: 0.1709 - val_loss: 0.0539 - val_mean_absolute_error: 0.1626\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0730 - mean_absolute_error: 0.1690 - val_loss: 0.0525 - val_mean_absolute_error: 0.1605\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0716 - mean_absolute_error: 0.1672 - val_loss: 0.0514 - val_mean_absolute_error: 0.1588\n",
      "Epoch 13/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0703 - mean_absolute_error: 0.1658 - val_loss: 0.0503 - val_mean_absolute_error: 0.1571\n",
      "Epoch 14/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0692 - mean_absolute_error: 0.1646 - val_loss: 0.0495 - val_mean_absolute_error: 0.1560\n",
      "Epoch 15/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0683 - mean_absolute_error: 0.1635 - val_loss: 0.0487 - val_mean_absolute_error: 0.1547\n",
      "Epoch 16/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0675 - mean_absolute_error: 0.1626 - val_loss: 0.0482 - val_mean_absolute_error: 0.1540\n",
      "Epoch 17/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0669 - mean_absolute_error: 0.1618 - val_loss: 0.0478 - val_mean_absolute_error: 0.1531\n",
      "Epoch 18/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0663 - mean_absolute_error: 0.1610 - val_loss: 0.0475 - val_mean_absolute_error: 0.1526\n",
      "Epoch 19/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0658 - mean_absolute_error: 0.1603 - val_loss: 0.0471 - val_mean_absolute_error: 0.1521\n",
      "Epoch 20/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0653 - mean_absolute_error: 0.1597 - val_loss: 0.0468 - val_mean_absolute_error: 0.1514\n",
      "Epoch 21/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0648 - mean_absolute_error: 0.1590 - val_loss: 0.0465 - val_mean_absolute_error: 0.1510\n",
      "Epoch 22/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0644 - mean_absolute_error: 0.1584 - val_loss: 0.0462 - val_mean_absolute_error: 0.1504\n",
      "Epoch 23/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0640 - mean_absolute_error: 0.1577 - val_loss: 0.0457 - val_mean_absolute_error: 0.1495\n",
      "Epoch 24/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0636 - mean_absolute_error: 0.1572 - val_loss: 0.0456 - val_mean_absolute_error: 0.1492\n",
      "Epoch 25/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0632 - mean_absolute_error: 0.1564 - val_loss: 0.0453 - val_mean_absolute_error: 0.1485\n",
      "Epoch 26/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0629 - mean_absolute_error: 0.1560 - val_loss: 0.0450 - val_mean_absolute_error: 0.1479\n",
      "Epoch 27/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0625 - mean_absolute_error: 0.1554 - val_loss: 0.0448 - val_mean_absolute_error: 0.1473\n",
      "Epoch 28/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0622 - mean_absolute_error: 0.1549 - val_loss: 0.0446 - val_mean_absolute_error: 0.1469\n",
      "Epoch 29/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0619 - mean_absolute_error: 0.1543 - val_loss: 0.0442 - val_mean_absolute_error: 0.1462\n",
      "Epoch 30/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0616 - mean_absolute_error: 0.1539 - val_loss: 0.0441 - val_mean_absolute_error: 0.1458\n",
      "Epoch 31/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0613 - mean_absolute_error: 0.1535 - val_loss: 0.0440 - val_mean_absolute_error: 0.1454\n",
      "Epoch 32/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0610 - mean_absolute_error: 0.1528 - val_loss: 0.0436 - val_mean_absolute_error: 0.1448\n",
      "Epoch 33/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0607 - mean_absolute_error: 0.1522 - val_loss: 0.0434 - val_mean_absolute_error: 0.1442\n",
      "Epoch 34/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0604 - mean_absolute_error: 0.1519 - val_loss: 0.0432 - val_mean_absolute_error: 0.1437\n",
      "Epoch 35/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0602 - mean_absolute_error: 0.1514 - val_loss: 0.0428 - val_mean_absolute_error: 0.1429\n",
      "Epoch 36/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0599 - mean_absolute_error: 0.1510 - val_loss: 0.0428 - val_mean_absolute_error: 0.1428\n",
      "Epoch 37/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0597 - mean_absolute_error: 0.1505 - val_loss: 0.0426 - val_mean_absolute_error: 0.1422\n",
      "Epoch 38/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0594 - mean_absolute_error: 0.1503 - val_loss: 0.0425 - val_mean_absolute_error: 0.1419\n",
      "Epoch 39/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0592 - mean_absolute_error: 0.1496 - val_loss: 0.0423 - val_mean_absolute_error: 0.1412\n",
      "Epoch 40/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0589 - mean_absolute_error: 0.1492 - val_loss: 0.0419 - val_mean_absolute_error: 0.1407\n",
      "Epoch 41/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0587 - mean_absolute_error: 0.1489 - val_loss: 0.0417 - val_mean_absolute_error: 0.1399\n",
      "Epoch 42/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0585 - mean_absolute_error: 0.1484 - val_loss: 0.0417 - val_mean_absolute_error: 0.1399\n",
      "Epoch 43/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0584 - mean_absolute_error: 0.1482 - val_loss: 0.0412 - val_mean_absolute_error: 0.1389\n",
      "Epoch 44/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0581 - mean_absolute_error: 0.1477 - val_loss: 0.0411 - val_mean_absolute_error: 0.1385\n",
      "Epoch 45/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0579 - mean_absolute_error: 0.1475 - val_loss: 0.0412 - val_mean_absolute_error: 0.1383\n",
      "Epoch 46/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0577 - mean_absolute_error: 0.1471 - val_loss: 0.0410 - val_mean_absolute_error: 0.1377\n",
      "Epoch 47/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0575 - mean_absolute_error: 0.1468 - val_loss: 0.0407 - val_mean_absolute_error: 0.1373\n",
      "Epoch 48/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0573 - mean_absolute_error: 0.1467 - val_loss: 0.0405 - val_mean_absolute_error: 0.1367\n",
      "Epoch 49/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0571 - mean_absolute_error: 0.1461 - val_loss: 0.0403 - val_mean_absolute_error: 0.1364\n",
      "Epoch 50/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0569 - mean_absolute_error: 0.1459 - val_loss: 0.0402 - val_mean_absolute_error: 0.1361\n",
      "Epoch 51/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0568 - mean_absolute_error: 0.1459 - val_loss: 0.0402 - val_mean_absolute_error: 0.1357\n",
      "Epoch 52/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0566 - mean_absolute_error: 0.1454 - val_loss: 0.0399 - val_mean_absolute_error: 0.1352\n",
      "Epoch 53/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0564 - mean_absolute_error: 0.1450 - val_loss: 0.0396 - val_mean_absolute_error: 0.1347\n",
      "Epoch 54/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0562 - mean_absolute_error: 0.1447 - val_loss: 0.0396 - val_mean_absolute_error: 0.1343\n",
      "Epoch 55/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0560 - mean_absolute_error: 0.1443 - val_loss: 0.0395 - val_mean_absolute_error: 0.1341\n",
      "Epoch 56/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0559 - mean_absolute_error: 0.1441 - val_loss: 0.0394 - val_mean_absolute_error: 0.1336\n",
      "Epoch 57/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0557 - mean_absolute_error: 0.1437 - val_loss: 0.0393 - val_mean_absolute_error: 0.1333\n",
      "Epoch 58/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0555 - mean_absolute_error: 0.1435 - val_loss: 0.0389 - val_mean_absolute_error: 0.1325\n",
      "Epoch 59/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0553 - mean_absolute_error: 0.1431 - val_loss: 0.0388 - val_mean_absolute_error: 0.1325\n",
      "Epoch 60/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0552 - mean_absolute_error: 0.1428 - val_loss: 0.0388 - val_mean_absolute_error: 0.1323\n",
      "Epoch 61/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0551 - mean_absolute_error: 0.1424 - val_loss: 0.0389 - val_mean_absolute_error: 0.1325\n",
      "Epoch 62/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0550 - mean_absolute_error: 0.1424 - val_loss: 0.0388 - val_mean_absolute_error: 0.1320\n",
      "Epoch 63/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0548 - mean_absolute_error: 0.1421 - val_loss: 0.0387 - val_mean_absolute_error: 0.1319\n",
      "Epoch 64/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0547 - mean_absolute_error: 0.1417 - val_loss: 0.0383 - val_mean_absolute_error: 0.1313\n",
      "Epoch 65/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0546 - mean_absolute_error: 0.1416 - val_loss: 0.0383 - val_mean_absolute_error: 0.1310\n",
      "Epoch 66/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0545 - mean_absolute_error: 0.1414 - val_loss: 0.0382 - val_mean_absolute_error: 0.1309\n",
      "Epoch 67/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0544 - mean_absolute_error: 0.1412 - val_loss: 0.0383 - val_mean_absolute_error: 0.1307\n",
      "Epoch 68/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0543 - mean_absolute_error: 0.1409 - val_loss: 0.0381 - val_mean_absolute_error: 0.1304\n",
      "Epoch 69/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0542 - mean_absolute_error: 0.1408 - val_loss: 0.0383 - val_mean_absolute_error: 0.1305\n",
      "Epoch 70/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0540 - mean_absolute_error: 0.1406 - val_loss: 0.0380 - val_mean_absolute_error: 0.1299\n",
      "Epoch 71/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0540 - mean_absolute_error: 0.1405 - val_loss: 0.0379 - val_mean_absolute_error: 0.1297\n",
      "Epoch 72/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0538 - mean_absolute_error: 0.1402 - val_loss: 0.0378 - val_mean_absolute_error: 0.1293\n",
      "Epoch 73/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0538 - mean_absolute_error: 0.1401 - val_loss: 0.0376 - val_mean_absolute_error: 0.1290\n",
      "Epoch 74/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0537 - mean_absolute_error: 0.1399 - val_loss: 0.0377 - val_mean_absolute_error: 0.1290\n",
      "Epoch 75/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0536 - mean_absolute_error: 0.1398 - val_loss: 0.0377 - val_mean_absolute_error: 0.1289\n",
      "Epoch 76/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0535 - mean_absolute_error: 0.1396 - val_loss: 0.0375 - val_mean_absolute_error: 0.1283\n",
      "Epoch 77/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0534 - mean_absolute_error: 0.1395 - val_loss: 0.0374 - val_mean_absolute_error: 0.1280\n",
      "Epoch 78/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1392 - val_loss: 0.0377 - val_mean_absolute_error: 0.1288\n",
      "Epoch 79/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0533 - mean_absolute_error: 0.1391 - val_loss: 0.0372 - val_mean_absolute_error: 0.1278\n",
      "Epoch 80/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0532 - mean_absolute_error: 0.1389 - val_loss: 0.0371 - val_mean_absolute_error: 0.1272\n",
      "Epoch 81/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0531 - mean_absolute_error: 0.1390 - val_loss: 0.0372 - val_mean_absolute_error: 0.1275\n",
      "Epoch 82/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0530 - mean_absolute_error: 0.1387 - val_loss: 0.0372 - val_mean_absolute_error: 0.1275\n",
      "Epoch 83/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0529 - mean_absolute_error: 0.1383 - val_loss: 0.0371 - val_mean_absolute_error: 0.1272\n",
      "Epoch 84/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1381 - val_loss: 0.0371 - val_mean_absolute_error: 0.1275\n",
      "Epoch 85/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0528 - mean_absolute_error: 0.1380 - val_loss: 0.0371 - val_mean_absolute_error: 0.1272\n",
      "Epoch 86/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0527 - mean_absolute_error: 0.1378 - val_loss: 0.0372 - val_mean_absolute_error: 0.1272\n",
      "Epoch 87/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0527 - mean_absolute_error: 0.1378 - val_loss: 0.0370 - val_mean_absolute_error: 0.1270\n",
      "Epoch 88/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0526 - mean_absolute_error: 0.1376 - val_loss: 0.0370 - val_mean_absolute_error: 0.1267\n",
      "Epoch 89/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0525 - mean_absolute_error: 0.1375 - val_loss: 0.0368 - val_mean_absolute_error: 0.1268\n",
      "Epoch 90/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0524 - mean_absolute_error: 0.1373 - val_loss: 0.0368 - val_mean_absolute_error: 0.1267\n",
      "Epoch 91/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1371 - val_loss: 0.0369 - val_mean_absolute_error: 0.1266\n",
      "Epoch 92/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0523 - mean_absolute_error: 0.1370 - val_loss: 0.0366 - val_mean_absolute_error: 0.1263\n",
      "Epoch 93/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0523 - mean_absolute_error: 0.1369 - val_loss: 0.0370 - val_mean_absolute_error: 0.1268\n",
      "Epoch 94/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1369 - val_loss: 0.0367 - val_mean_absolute_error: 0.1266\n",
      "Epoch 95/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0521 - mean_absolute_error: 0.1367 - val_loss: 0.0368 - val_mean_absolute_error: 0.1265\n",
      "Epoch 96/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1365 - val_loss: 0.0366 - val_mean_absolute_error: 0.1263\n",
      "Epoch 97/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1365 - val_loss: 0.0366 - val_mean_absolute_error: 0.1262\n",
      "Epoch 98/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1365 - val_loss: 0.0365 - val_mean_absolute_error: 0.1263\n",
      "Epoch 99/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1364 - val_loss: 0.0365 - val_mean_absolute_error: 0.1263\n",
      "Epoch 100/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0518 - mean_absolute_error: 0.1363 - val_loss: 0.0366 - val_mean_absolute_error: 0.1262\n",
      "Epoch 101/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0517 - mean_absolute_error: 0.1362 - val_loss: 0.0364 - val_mean_absolute_error: 0.1258\n",
      "Epoch 102/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0517 - mean_absolute_error: 0.1360 - val_loss: 0.0364 - val_mean_absolute_error: 0.1260\n",
      "Epoch 103/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0516 - mean_absolute_error: 0.1359 - val_loss: 0.0364 - val_mean_absolute_error: 0.1258\n",
      "Epoch 104/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1359 - val_loss: 0.0364 - val_mean_absolute_error: 0.1256\n",
      "Epoch 105/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1360 - val_loss: 0.0364 - val_mean_absolute_error: 0.1256\n",
      "Epoch 106/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0515 - mean_absolute_error: 0.1359 - val_loss: 0.0363 - val_mean_absolute_error: 0.1258\n",
      "Epoch 107/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1357 - val_loss: 0.0362 - val_mean_absolute_error: 0.1255\n",
      "Epoch 108/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1356 - val_loss: 0.0362 - val_mean_absolute_error: 0.1254\n",
      "Epoch 109/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0513 - mean_absolute_error: 0.1356 - val_loss: 0.0362 - val_mean_absolute_error: 0.1257\n",
      "Epoch 110/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0513 - mean_absolute_error: 0.1356 - val_loss: 0.0361 - val_mean_absolute_error: 0.1253\n",
      "Epoch 111/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0513 - mean_absolute_error: 0.1357 - val_loss: 0.0363 - val_mean_absolute_error: 0.1255\n",
      "Epoch 112/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0512 - mean_absolute_error: 0.1353 - val_loss: 0.0361 - val_mean_absolute_error: 0.1252\n",
      "Epoch 113/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0511 - mean_absolute_error: 0.1353 - val_loss: 0.0361 - val_mean_absolute_error: 0.1253\n",
      "Epoch 114/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0511 - mean_absolute_error: 0.1353 - val_loss: 0.0361 - val_mean_absolute_error: 0.1255\n",
      "Epoch 115/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0510 - mean_absolute_error: 0.1351 - val_loss: 0.0359 - val_mean_absolute_error: 0.1251\n",
      "Epoch 116/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0510 - mean_absolute_error: 0.1351 - val_loss: 0.0360 - val_mean_absolute_error: 0.1251\n",
      "Epoch 117/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0509 - mean_absolute_error: 0.1350 - val_loss: 0.0360 - val_mean_absolute_error: 0.1253\n",
      "Epoch 118/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0509 - mean_absolute_error: 0.1350 - val_loss: 0.0357 - val_mean_absolute_error: 0.1248\n",
      "Epoch 119/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0508 - mean_absolute_error: 0.1351 - val_loss: 0.0360 - val_mean_absolute_error: 0.1253\n",
      "Epoch 120/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0508 - mean_absolute_error: 0.1347 - val_loss: 0.0358 - val_mean_absolute_error: 0.1249\n",
      "Epoch 121/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0508 - mean_absolute_error: 0.1348 - val_loss: 0.0360 - val_mean_absolute_error: 0.1253\n",
      "Epoch 122/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0507 - mean_absolute_error: 0.1348 - val_loss: 0.0359 - val_mean_absolute_error: 0.1251\n",
      "Epoch 123/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0507 - mean_absolute_error: 0.1346 - val_loss: 0.0356 - val_mean_absolute_error: 0.1247\n",
      "Epoch 124/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0507 - mean_absolute_error: 0.1346 - val_loss: 0.0362 - val_mean_absolute_error: 0.1255\n",
      "Epoch 125/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0506 - mean_absolute_error: 0.1344 - val_loss: 0.0358 - val_mean_absolute_error: 0.1247\n",
      "Epoch 126/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0506 - mean_absolute_error: 0.1345 - val_loss: 0.0359 - val_mean_absolute_error: 0.1253\n",
      "Epoch 127/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0505 - mean_absolute_error: 0.1345 - val_loss: 0.0358 - val_mean_absolute_error: 0.1250\n",
      "Epoch 128/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0505 - mean_absolute_error: 0.1344 - val_loss: 0.0358 - val_mean_absolute_error: 0.1249\n"
     ]
    }
   ],
   "source": [
    "history_mlp = tiny_trainer(model=mlp_model_05b, model_name='mlp_05b', window_generator=window_6, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "202/202 [==============================] - 3s 3ms/step - loss: 0.9604 - mean_absolute_error: 0.7825 - val_loss: 1.2828 - val_mean_absolute_error: 0.9182\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.8291 - mean_absolute_error: 0.7245 - val_loss: 1.0530 - val_mean_absolute_error: 0.8176\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.5745 - mean_absolute_error: 0.5812 - val_loss: 0.5992 - val_mean_absolute_error: 0.5903\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.2825 - mean_absolute_error: 0.3915 - val_loss: 0.2579 - val_mean_absolute_error: 0.3691\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.1378 - mean_absolute_error: 0.2562 - val_loss: 0.1149 - val_mean_absolute_error: 0.2364\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0960 - mean_absolute_error: 0.2005 - val_loss: 0.0780 - val_mean_absolute_error: 0.1935\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0867 - mean_absolute_error: 0.1851 - val_loss: 0.0682 - val_mean_absolute_error: 0.1805\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0827 - mean_absolute_error: 0.1787 - val_loss: 0.0641 - val_mean_absolute_error: 0.1740\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0800 - mean_absolute_error: 0.1741 - val_loss: 0.0615 - val_mean_absolute_error: 0.1694\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0777 - mean_absolute_error: 0.1704 - val_loss: 0.0596 - val_mean_absolute_error: 0.1657\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0757 - mean_absolute_error: 0.1673 - val_loss: 0.0582 - val_mean_absolute_error: 0.1627\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0741 - mean_absolute_error: 0.1647 - val_loss: 0.0571 - val_mean_absolute_error: 0.1604\n",
      "Epoch 13/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.1625 - val_loss: 0.0559 - val_mean_absolute_error: 0.1582\n",
      "Epoch 14/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0715 - mean_absolute_error: 0.1605 - val_loss: 0.0553 - val_mean_absolute_error: 0.1564\n",
      "Epoch 15/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0705 - mean_absolute_error: 0.1589 - val_loss: 0.0545 - val_mean_absolute_error: 0.1547\n",
      "Epoch 16/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0695 - mean_absolute_error: 0.1574 - val_loss: 0.0538 - val_mean_absolute_error: 0.1532\n",
      "Epoch 17/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0687 - mean_absolute_error: 0.1561 - val_loss: 0.0533 - val_mean_absolute_error: 0.1521\n",
      "Epoch 18/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0680 - mean_absolute_error: 0.1550 - val_loss: 0.0529 - val_mean_absolute_error: 0.1511\n",
      "Epoch 19/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0673 - mean_absolute_error: 0.1541 - val_loss: 0.0525 - val_mean_absolute_error: 0.1502\n",
      "Epoch 20/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0667 - mean_absolute_error: 0.1533 - val_loss: 0.0522 - val_mean_absolute_error: 0.1495\n",
      "Epoch 21/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0662 - mean_absolute_error: 0.1527 - val_loss: 0.0518 - val_mean_absolute_error: 0.1488\n",
      "Epoch 22/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0657 - mean_absolute_error: 0.1520 - val_loss: 0.0515 - val_mean_absolute_error: 0.1482\n",
      "Epoch 23/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0653 - mean_absolute_error: 0.1514 - val_loss: 0.0512 - val_mean_absolute_error: 0.1478\n",
      "Epoch 24/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0649 - mean_absolute_error: 0.1510 - val_loss: 0.0509 - val_mean_absolute_error: 0.1472\n",
      "Epoch 25/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0645 - mean_absolute_error: 0.1506 - val_loss: 0.0507 - val_mean_absolute_error: 0.1469\n",
      "Epoch 26/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0641 - mean_absolute_error: 0.1501 - val_loss: 0.0502 - val_mean_absolute_error: 0.1463\n",
      "Epoch 27/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0638 - mean_absolute_error: 0.1497 - val_loss: 0.0499 - val_mean_absolute_error: 0.1458\n",
      "Epoch 28/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0635 - mean_absolute_error: 0.1495 - val_loss: 0.0497 - val_mean_absolute_error: 0.1455\n",
      "Epoch 29/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0631 - mean_absolute_error: 0.1492 - val_loss: 0.0497 - val_mean_absolute_error: 0.1452\n",
      "Epoch 30/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0628 - mean_absolute_error: 0.1487 - val_loss: 0.0493 - val_mean_absolute_error: 0.1448\n",
      "Epoch 31/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0625 - mean_absolute_error: 0.1484 - val_loss: 0.0489 - val_mean_absolute_error: 0.1443\n",
      "Epoch 32/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0622 - mean_absolute_error: 0.1481 - val_loss: 0.0488 - val_mean_absolute_error: 0.1442\n",
      "Epoch 33/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0619 - mean_absolute_error: 0.1476 - val_loss: 0.0485 - val_mean_absolute_error: 0.1437\n",
      "Epoch 34/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0617 - mean_absolute_error: 0.1474 - val_loss: 0.0484 - val_mean_absolute_error: 0.1434\n",
      "Epoch 35/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0614 - mean_absolute_error: 0.1471 - val_loss: 0.0479 - val_mean_absolute_error: 0.1428\n",
      "Epoch 36/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0611 - mean_absolute_error: 0.1469 - val_loss: 0.0479 - val_mean_absolute_error: 0.1426\n",
      "Epoch 37/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0609 - mean_absolute_error: 0.1466 - val_loss: 0.0476 - val_mean_absolute_error: 0.1424\n",
      "Epoch 38/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0606 - mean_absolute_error: 0.1462 - val_loss: 0.0475 - val_mean_absolute_error: 0.1422\n",
      "Epoch 39/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0604 - mean_absolute_error: 0.1459 - val_loss: 0.0472 - val_mean_absolute_error: 0.1417\n",
      "Epoch 40/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0601 - mean_absolute_error: 0.1456 - val_loss: 0.0471 - val_mean_absolute_error: 0.1414\n",
      "Epoch 41/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0599 - mean_absolute_error: 0.1453 - val_loss: 0.0469 - val_mean_absolute_error: 0.1412\n",
      "Epoch 42/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0597 - mean_absolute_error: 0.1453 - val_loss: 0.0467 - val_mean_absolute_error: 0.1409\n",
      "Epoch 43/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0594 - mean_absolute_error: 0.1448 - val_loss: 0.0467 - val_mean_absolute_error: 0.1409\n",
      "Epoch 44/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0593 - mean_absolute_error: 0.1446 - val_loss: 0.0463 - val_mean_absolute_error: 0.1403\n",
      "Epoch 45/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0590 - mean_absolute_error: 0.1445 - val_loss: 0.0463 - val_mean_absolute_error: 0.1405\n",
      "Epoch 46/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0588 - mean_absolute_error: 0.1442 - val_loss: 0.0461 - val_mean_absolute_error: 0.1402\n",
      "Epoch 47/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0586 - mean_absolute_error: 0.1439 - val_loss: 0.0460 - val_mean_absolute_error: 0.1399\n",
      "Epoch 48/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0584 - mean_absolute_error: 0.1438 - val_loss: 0.0456 - val_mean_absolute_error: 0.1397\n",
      "Epoch 49/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0583 - mean_absolute_error: 0.1435 - val_loss: 0.0457 - val_mean_absolute_error: 0.1396\n",
      "Epoch 50/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0581 - mean_absolute_error: 0.1433 - val_loss: 0.0456 - val_mean_absolute_error: 0.1393\n",
      "Epoch 51/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0579 - mean_absolute_error: 0.1433 - val_loss: 0.0453 - val_mean_absolute_error: 0.1390\n",
      "Epoch 52/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0577 - mean_absolute_error: 0.1430 - val_loss: 0.0452 - val_mean_absolute_error: 0.1388\n",
      "Epoch 53/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0576 - mean_absolute_error: 0.1427 - val_loss: 0.0451 - val_mean_absolute_error: 0.1386\n",
      "Epoch 54/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0574 - mean_absolute_error: 0.1427 - val_loss: 0.0449 - val_mean_absolute_error: 0.1385\n",
      "Epoch 55/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0573 - mean_absolute_error: 0.1424 - val_loss: 0.0449 - val_mean_absolute_error: 0.1387\n",
      "Epoch 56/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0571 - mean_absolute_error: 0.1423 - val_loss: 0.0447 - val_mean_absolute_error: 0.1380\n",
      "Epoch 57/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0569 - mean_absolute_error: 0.1419 - val_loss: 0.0444 - val_mean_absolute_error: 0.1379\n",
      "Epoch 58/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0568 - mean_absolute_error: 0.1418 - val_loss: 0.0445 - val_mean_absolute_error: 0.1378\n",
      "Epoch 59/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0567 - mean_absolute_error: 0.1416 - val_loss: 0.0444 - val_mean_absolute_error: 0.1375\n",
      "Epoch 60/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0565 - mean_absolute_error: 0.1414 - val_loss: 0.0441 - val_mean_absolute_error: 0.1373\n",
      "Epoch 61/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0563 - mean_absolute_error: 0.1413 - val_loss: 0.0440 - val_mean_absolute_error: 0.1370\n",
      "Epoch 62/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0562 - mean_absolute_error: 0.1412 - val_loss: 0.0441 - val_mean_absolute_error: 0.1372\n",
      "Epoch 63/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0561 - mean_absolute_error: 0.1409 - val_loss: 0.0440 - val_mean_absolute_error: 0.1368\n",
      "Epoch 64/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0560 - mean_absolute_error: 0.1407 - val_loss: 0.0437 - val_mean_absolute_error: 0.1365\n",
      "Epoch 65/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0558 - mean_absolute_error: 0.1406 - val_loss: 0.0437 - val_mean_absolute_error: 0.1364\n",
      "Epoch 66/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0557 - mean_absolute_error: 0.1406 - val_loss: 0.0434 - val_mean_absolute_error: 0.1361\n",
      "Epoch 67/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0556 - mean_absolute_error: 0.1403 - val_loss: 0.0433 - val_mean_absolute_error: 0.1359\n",
      "Epoch 68/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0555 - mean_absolute_error: 0.1404 - val_loss: 0.0432 - val_mean_absolute_error: 0.1360\n",
      "Epoch 69/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0554 - mean_absolute_error: 0.1402 - val_loss: 0.0431 - val_mean_absolute_error: 0.1359\n",
      "Epoch 70/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0552 - mean_absolute_error: 0.1399 - val_loss: 0.0430 - val_mean_absolute_error: 0.1356\n",
      "Epoch 71/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0552 - mean_absolute_error: 0.1399 - val_loss: 0.0428 - val_mean_absolute_error: 0.1354\n",
      "Epoch 72/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0551 - mean_absolute_error: 0.1399 - val_loss: 0.0427 - val_mean_absolute_error: 0.1352\n",
      "Epoch 73/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0550 - mean_absolute_error: 0.1397 - val_loss: 0.0425 - val_mean_absolute_error: 0.1349\n",
      "Epoch 74/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0549 - mean_absolute_error: 0.1397 - val_loss: 0.0423 - val_mean_absolute_error: 0.1346\n",
      "Epoch 75/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0548 - mean_absolute_error: 0.1394 - val_loss: 0.0423 - val_mean_absolute_error: 0.1344\n",
      "Epoch 76/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0547 - mean_absolute_error: 0.1394 - val_loss: 0.0419 - val_mean_absolute_error: 0.1341\n",
      "Epoch 77/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0546 - mean_absolute_error: 0.1392 - val_loss: 0.0419 - val_mean_absolute_error: 0.1338\n",
      "Epoch 78/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0545 - mean_absolute_error: 0.1391 - val_loss: 0.0419 - val_mean_absolute_error: 0.1335\n",
      "Epoch 79/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0544 - mean_absolute_error: 0.1392 - val_loss: 0.0416 - val_mean_absolute_error: 0.1333\n",
      "Epoch 80/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0543 - mean_absolute_error: 0.1389 - val_loss: 0.0415 - val_mean_absolute_error: 0.1331\n",
      "Epoch 81/500\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.0542 - mean_absolute_error: 0.1389 - val_loss: 0.0414 - val_mean_absolute_error: 0.1331\n",
      "Epoch 82/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0540 - mean_absolute_error: 0.1386 - val_loss: 0.0410 - val_mean_absolute_error: 0.1328\n",
      "Epoch 83/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0539 - mean_absolute_error: 0.1385 - val_loss: 0.0410 - val_mean_absolute_error: 0.1323\n",
      "Epoch 84/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0539 - mean_absolute_error: 0.1383 - val_loss: 0.0410 - val_mean_absolute_error: 0.1321\n",
      "Epoch 85/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0538 - mean_absolute_error: 0.1383 - val_loss: 0.0409 - val_mean_absolute_error: 0.1320\n",
      "Epoch 86/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0537 - mean_absolute_error: 0.1381 - val_loss: 0.0405 - val_mean_absolute_error: 0.1316\n",
      "Epoch 87/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0536 - mean_absolute_error: 0.1380 - val_loss: 0.0405 - val_mean_absolute_error: 0.1315\n",
      "Epoch 88/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0535 - mean_absolute_error: 0.1379 - val_loss: 0.0406 - val_mean_absolute_error: 0.1317\n",
      "Epoch 89/500\n",
      "202/202 [==============================] - 1s 4ms/step - loss: 0.0534 - mean_absolute_error: 0.1380 - val_loss: 0.0406 - val_mean_absolute_error: 0.1316\n",
      "Epoch 90/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0533 - mean_absolute_error: 0.1377 - val_loss: 0.0406 - val_mean_absolute_error: 0.1317\n",
      "Epoch 91/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0533 - mean_absolute_error: 0.1377 - val_loss: 0.0404 - val_mean_absolute_error: 0.1314\n",
      "Epoch 92/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0532 - mean_absolute_error: 0.1377 - val_loss: 0.0400 - val_mean_absolute_error: 0.1310\n",
      "Epoch 93/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0532 - mean_absolute_error: 0.1376 - val_loss: 0.0401 - val_mean_absolute_error: 0.1310\n",
      "Epoch 94/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1373 - val_loss: 0.0399 - val_mean_absolute_error: 0.1308\n",
      "Epoch 95/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1373 - val_loss: 0.0399 - val_mean_absolute_error: 0.1310\n",
      "Epoch 96/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1374 - val_loss: 0.0401 - val_mean_absolute_error: 0.1311\n",
      "Epoch 97/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0529 - mean_absolute_error: 0.1371 - val_loss: 0.0400 - val_mean_absolute_error: 0.1311\n",
      "Epoch 98/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1372 - val_loss: 0.0399 - val_mean_absolute_error: 0.1308\n",
      "Epoch 99/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1369 - val_loss: 0.0400 - val_mean_absolute_error: 0.1308\n"
     ]
    }
   ],
   "source": [
    "history_mlp = tiny_trainer(model=mlp_model_10b, model_name='mlp_10b', window_generator=window_6, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.6907 - mean_absolute_error: 0.6476 - val_loss: 0.2728 - val_mean_absolute_error: 0.4026\n",
      "Epoch 2/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.1176 - mean_absolute_error: 0.2354 - val_loss: 0.0663 - val_mean_absolute_error: 0.1725\n",
      "Epoch 3/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0813 - mean_absolute_error: 0.1749 - val_loss: 0.0606 - val_mean_absolute_error: 0.1645\n",
      "Epoch 4/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0781 - mean_absolute_error: 0.1695 - val_loss: 0.0577 - val_mean_absolute_error: 0.1599\n",
      "Epoch 5/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0749 - mean_absolute_error: 0.1650 - val_loss: 0.0551 - val_mean_absolute_error: 0.1561\n",
      "Epoch 6/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.1617 - val_loss: 0.0530 - val_mean_absolute_error: 0.1531\n",
      "Epoch 7/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0704 - mean_absolute_error: 0.1591 - val_loss: 0.0515 - val_mean_absolute_error: 0.1504\n",
      "Epoch 8/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0684 - mean_absolute_error: 0.1567 - val_loss: 0.0496 - val_mean_absolute_error: 0.1476\n",
      "Epoch 9/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0664 - mean_absolute_error: 0.1545 - val_loss: 0.0480 - val_mean_absolute_error: 0.1447\n",
      "Epoch 10/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0648 - mean_absolute_error: 0.1527 - val_loss: 0.0468 - val_mean_absolute_error: 0.1433\n",
      "Epoch 11/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0635 - mean_absolute_error: 0.1508 - val_loss: 0.0457 - val_mean_absolute_error: 0.1414\n",
      "Epoch 12/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0623 - mean_absolute_error: 0.1494 - val_loss: 0.0445 - val_mean_absolute_error: 0.1398\n",
      "Epoch 13/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0612 - mean_absolute_error: 0.1480 - val_loss: 0.0434 - val_mean_absolute_error: 0.1378\n",
      "Epoch 14/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0601 - mean_absolute_error: 0.1464 - val_loss: 0.0428 - val_mean_absolute_error: 0.1376\n",
      "Epoch 15/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0589 - mean_absolute_error: 0.1452 - val_loss: 0.0427 - val_mean_absolute_error: 0.1364\n",
      "Epoch 16/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0578 - mean_absolute_error: 0.1438 - val_loss: 0.0424 - val_mean_absolute_error: 0.1358\n",
      "Epoch 17/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0569 - mean_absolute_error: 0.1430 - val_loss: 0.0416 - val_mean_absolute_error: 0.1351\n",
      "Epoch 18/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0558 - mean_absolute_error: 0.1418 - val_loss: 0.0417 - val_mean_absolute_error: 0.1355\n",
      "Epoch 19/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0551 - mean_absolute_error: 0.1412 - val_loss: 0.0404 - val_mean_absolute_error: 0.1342\n",
      "Epoch 20/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0544 - mean_absolute_error: 0.1404 - val_loss: 0.0410 - val_mean_absolute_error: 0.1342\n",
      "Epoch 21/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0539 - mean_absolute_error: 0.1398 - val_loss: 0.0397 - val_mean_absolute_error: 0.1324\n",
      "Epoch 22/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0533 - mean_absolute_error: 0.1389 - val_loss: 0.0398 - val_mean_absolute_error: 0.1330\n",
      "Epoch 23/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0531 - mean_absolute_error: 0.1392 - val_loss: 0.0392 - val_mean_absolute_error: 0.1316\n",
      "Epoch 24/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1385 - val_loss: 0.0401 - val_mean_absolute_error: 0.1325\n",
      "Epoch 25/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1380 - val_loss: 0.0394 - val_mean_absolute_error: 0.1321\n",
      "Epoch 26/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1380 - val_loss: 0.0390 - val_mean_absolute_error: 0.1314\n",
      "Epoch 27/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1377 - val_loss: 0.0387 - val_mean_absolute_error: 0.1301\n",
      "Epoch 28/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0518 - mean_absolute_error: 0.1374 - val_loss: 0.0389 - val_mean_absolute_error: 0.1303\n",
      "Epoch 29/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0516 - mean_absolute_error: 0.1370 - val_loss: 0.0386 - val_mean_absolute_error: 0.1312\n",
      "Epoch 30/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0515 - mean_absolute_error: 0.1370 - val_loss: 0.0394 - val_mean_absolute_error: 0.1316\n",
      "Epoch 31/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1370 - val_loss: 0.0386 - val_mean_absolute_error: 0.1308\n",
      "Epoch 32/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0514 - mean_absolute_error: 0.1366 - val_loss: 0.0383 - val_mean_absolute_error: 0.1317\n",
      "Epoch 33/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0510 - mean_absolute_error: 0.1364 - val_loss: 0.0388 - val_mean_absolute_error: 0.1304\n",
      "Epoch 34/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0508 - mean_absolute_error: 0.1361 - val_loss: 0.0384 - val_mean_absolute_error: 0.1300\n",
      "Epoch 35/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0508 - mean_absolute_error: 0.1361 - val_loss: 0.0385 - val_mean_absolute_error: 0.1313\n",
      "Epoch 36/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0507 - mean_absolute_error: 0.1362 - val_loss: 0.0382 - val_mean_absolute_error: 0.1304\n",
      "Epoch 37/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0506 - mean_absolute_error: 0.1359 - val_loss: 0.0383 - val_mean_absolute_error: 0.1309\n",
      "Epoch 38/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0505 - mean_absolute_error: 0.1358 - val_loss: 0.0378 - val_mean_absolute_error: 0.1293\n",
      "Epoch 39/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0503 - mean_absolute_error: 0.1355 - val_loss: 0.0390 - val_mean_absolute_error: 0.1318\n",
      "Epoch 40/500\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.0503 - mean_absolute_error: 0.1353 - val_loss: 0.0380 - val_mean_absolute_error: 0.1301\n",
      "Epoch 41/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0501 - mean_absolute_error: 0.1353 - val_loss: 0.0380 - val_mean_absolute_error: 0.1303\n",
      "Epoch 42/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0501 - mean_absolute_error: 0.1353 - val_loss: 0.0382 - val_mean_absolute_error: 0.1314\n",
      "Epoch 43/500\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.0500 - mean_absolute_error: 0.1352 - val_loss: 0.0386 - val_mean_absolute_error: 0.1308\n"
     ]
    }
   ],
   "source": [
    "history_mlp = tiny_trainer(model=mlp_model_20b, model_name='mlp_20b', window_generator=window_6, max_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {\n",
    "    'mlp_05': mlp_model_05,\n",
    "    'mlp_10': mlp_model_10,\n",
    "    'mlp_20': mlp_model_20,\n",
    "    'mlp_05b': mlp_model_05b,\n",
    "    'mlp_10b': mlp_model_10b,\n",
    "    'mlp_20b': mlp_model_20b,\n",
    "}\n",
    "\n",
    "for n in trained_models:\n",
    "    trained_models[n].save(r'models/line_temp_model_{}_15_mins.hdf5'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test model: persistence\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0388 - mean_absolute_error: 0.1325\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0465 - mean_absolute_error: 0.1445\n",
      "Test model: mlp_05\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0365 - mean_absolute_error: 0.1301\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0495 - mean_absolute_error: 0.1507\n",
      "Number of parameters: 71\n",
      "FS_test = -0.0429, FS_val = 0.0179\n",
      "Test model: mlp_10\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0375 - mean_absolute_error: 0.1300\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0475 - mean_absolute_error: 0.1477\n",
      "Number of parameters: 191\n",
      "FS_test = -0.0224, FS_val = 0.0184\n",
      "Test model: mlp_20\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0382 - mean_absolute_error: 0.1291\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0464 - mean_absolute_error: 0.1460\n",
      "Number of parameters: 581\n",
      "FS_test = -0.0106, FS_val = 0.0255\n",
      "Test model: mlp_05b\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0358 - mean_absolute_error: 0.1249\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0450 - mean_absolute_error: 0.1430\n",
      "Number of parameters: 101\n",
      "FS_test = 0.00982, FS_val = 0.0567\n",
      "Test model: mlp_10b\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0400 - mean_absolute_error: 0.1308\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0471 - mean_absolute_error: 0.1450\n",
      "Number of parameters: 301\n",
      "FS_test = -0.00381, FS_val = 0.0125\n",
      "Test model: mlp_20b\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0386 - mean_absolute_error: 0.1308\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0466 - mean_absolute_error: 0.1485\n",
      "Number of parameters: 1001\n",
      "FS_test = -0.0283, FS_val = 0.0126\n"
     ]
    }
   ],
   "source": [
    "model_error_val = {}\n",
    "model_error_test = {}\n",
    "model_FS_test = {}\n",
    "\n",
    "print('Test model: persistence')\n",
    "model_error_val['persistance'] = persistance_model.evaluate(window_1.val, verbose=1)\n",
    "model_error_test['persistance'] = persistance_model.evaluate(window_1.test, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    print(f'Test model: {name}')\n",
    "    model_error_val[name] = model.evaluate(window_6.val, verbose=1)\n",
    "    model_error_test[name] = model.evaluate(window_6.test, verbose=1)\n",
    "    trainable_params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "    model_FS_test[name] = 1- (model_error_test[name][1] / model_error_test[\"persistance\"][1])\n",
    "\n",
    "    print(f'Number of parameters: {trainable_params}')\n",
    "    print(f'FS_test = {1- (model_error_test[name][1] / model_error_test[\"persistance\"][1]):.3}, FS_val = {1- (model_error_val[name][1] / model_error_val[\"persistance\"][1]):.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistance\n",
      "RMSE: 0.216\n",
      "MAE: 0.144\n",
      "mlp_05\n",
      "RMSE: 0.222\n",
      "MAE: 0.151\n",
      "mlp_10\n",
      "RMSE: 0.218\n",
      "MAE: 0.148\n",
      "mlp_20\n",
      "RMSE: 0.215\n",
      "MAE: 0.146\n",
      "mlp_05b\n",
      "RMSE: 0.212\n",
      "MAE: 0.143\n",
      "mlp_10b\n",
      "RMSE: 0.217\n",
      "MAE: 0.145\n",
      "mlp_20b\n",
      "RMSE: 0.216\n",
      "MAE: 0.149\n"
     ]
    }
   ],
   "source": [
    "for key in model_error_test:\n",
    "    print(key)\n",
    "    print(f'RMSE: {np.sqrt(model_error_test[key][0]):.03f}')\n",
    "    print(f'MAE: {model_error_test[key][1]:.03f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_5 = [-0.30703689139926404, -0.01422131780964464, -0.0005217070157221837, -0.018031434759318454, 0.03503366470308544, 0.08436101788320138]\n",
    "heights_10 = [-0.04333260114009341, 0.0188142712211391, -0.03838395983071763, -0.03985975506068984, 0.0479286104135771, 0.04025522073999588]\n",
    "heights_15 = [-0.04293350995875023, -0.02236810575739101, -0.010567094878774164, 0.00982418708485433, -0.003811709080938863, -0.028289809135001454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGFCAYAAAALnnwfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMNElEQVR4nO3deVxU9f4/8NcMICCyyk4g7pYGbkV+UXO7iKi4Zm6l6VVU0jS3a5m7uaZeQ01cseCaXanMckc0EykXMr3kkuJyAUVZBlDGYeb8/vDHXEcQzhxmYBhez8fjPOJsn/P+vDlH3n3OmTMyQRAEEBEREVGF5NUdABEREVFNwcKJiIiISCQWTkREREQisXAiIiIiEomFExEREZFILJyIiIiIRGLhRERERCQSCyciIiIikVg4EREREYnEwomIiIhIJMvqDuB5J0+exKpVq3Du3DlkZGTg22+/Rf/+/bXrBUHA/PnzsWXLFuTm5iI4OBibNm1C06ZNAQBKpRJ///vf8f3338PT0xMbN25Ejx49tPuvWrUKt2/fxueff65XXBqNBunp6bC3t4dMJjNIX4mIiKj6CYKA/Px8eHt7Qy6vYExJMDE//fST8PHHHwvx8fECAOHbb7/VWb98+XLB0dFR+O6774Tff/9dCA8PFxo2bCg8fvxYEARBWL9+vfDyyy8Lly5dElatWiW4ubkJGo1GEARBuHHjhtC0aVMhLy9P77ju3LkjAODEiRMnTpw4mel0586dCusBmSCY7pf8ymQynREnQRDg7e2N6dOnY8aMGQCAvLw8eHh4YOfOnRg6dCgmTZoEBwcHLF++HI8fP0bdunVx//59uLm5ITQ0FBERERgwYIDeseTl5cHJyQl37tyBg4ODIbtpEjQaDTIe5MDL1bniapt0MHfSMG/SMXfSMG/SmXvuFAoFfH19kZubC0dHx3K3NblbdeW5efMmMjMzdW69OTo6IigoCElJSRg6dCgCAwPx5Zdf4vHjxzh06BC8vLzg6uqK2NhY2NjYiC6alEollEqldj4/Px8AUK9ePdSrV8+wHTMBGo0Gdo9VqFevnlleFMbE3EnDvEnH3EnDvEln7rnTaDQAIOpRnBpVOGVmZgIAPDw8dJZ7eHho140ZMwYXL17EK6+8AldXV+zZswc5OTmYN28eEhMTMXfuXOzevRuNGzfG9u3b4ePjU+axli1bhoULF5ZanvEgBwXKYgP3rPppNBpk5SgACGZ5URgTcycN8yYdcycN8yadueeuZHBEjBpVOIlhZWWFDRs26Cx77733MGXKFFy4cAHfffcdfv/9d6xcuRJTpkzB3r17y2xnzpw5+PDDD7XzJcN4Xq7OZnurDpDB2808h2GNibmThnmTjrmThnmTztxzp7AWXw7VqMLJ09MTAHDv3j14eXlpl9+7dw+tW7cuc5/jx4/j8uXL2Lp1K2bOnImwsDDY2dlhyJAhiIqKeuGxrK2tYW1tXWq5XC43y5MGAORymVn3z5iYO2mYN+mYO2mYN+nMOXf69KlG9b5hw4bw9PTEsWPHtMsUCgWSk5PRoUOHUtsXFRUhMjISmzdvhoWFBdRqNVQqFQBApVJBrVZXWexERERU85lc4VRQUICUlBSkpKQAePpAeEpKCm7fvg2ZTIapU6diyZIl2LdvH/744w+8++678Pb21nnXU4nFixcjLCwMbdq0AQAEBwcjPj4eFy9eRFRUFIKDg6uwZ0RERFTTmdyturNnz6Jr167a+ZLnjEaNGoWdO3di1qxZKCwsxPjx45Gbm4uOHTvi4MGDsLGx0Wnn0qVL2LNnj7YAA4DBgwcjMTERnTp1QvPmzREXF1clfSIiIiLzYNLvcTIlCoUCjo6OyMvLM9uHw9OzsuHt5mKW96+NibmThnmTjrmThnmTztxzp8/fePPrPREREZGRsHAiIiIiEomFExEREZFILJyIiIiIRGLhRERERCSSyb2OgIiIiP7HpmmYQdsruvaTQdurbTjiRERERCQSCyciIiIikVg4EREREYnEwomIiIhIJBZORERERCKxcCIiIiISiYUTERERkUgsnIiIiIhEYuFEREREJBILJyIiIiKRWDgRERERicTCiYiIiEgkFk5EREREIrFwIiIiIhKJhRMRERGRSCyciIiIiERi4UREREQkEgsnIiIiIpFYOBERERGJxMKJiIiISCQWTkREREQi1bjCacGCBZDJZDpTixYttOs//PBDuLi4wNfXF7GxsTr7fvPNN+jbt29Vh0xERERmwrK6A5CiZcuWOHr0qHbe0vJpN3744QfExcXh8OHDuHbtGsaMGYOePXvC1dUVeXl5+Pjjj3X2IyIiItJHjRtxAp4WSp6entrJ1dUVAJCamoouXbqgffv2GDZsGBwcHHDz5k0AwKxZszBx4kT4+flVZ+hERERUg9XIEadr167B29sbNjY26NChA5YtWwY/Pz8EBgYiOjoaOTk5uHHjBh4/fowmTZrg1KlTOH/+PDZu3Cj6GEqlEkqlUjuvUCgAABqNBhqNxuB9qm5P+yWYZd+MjbmThnmTjrmTpqbmTSYzbHtS+l9TcyeWPv2qcYVTUFAQdu7ciebNmyMjIwMLFy5Ep06dcOnSJfTs2RMjR47Ea6+9BltbW8TExMDOzg4TJ07Ezp07sWnTJnz++edwdXVFdHQ0WrZs+cLjLFu2DAsXLiy1PONBDgqUxcbsYrXQaDTIylEAECCX18iByGrD3EnDvEnH3ElTU/PmWt/JoO2lZ2XrvU9NzZ1Y+fn5oreVCYIgGDEWo8vNzUWDBg2wZs0ajB07ttT6hQsXIjc3F++99x5CQkLwxx9/YP/+/YiKisK5c+de2G5ZI06+vr7IycmBg4ODUfpSnTQaDdKzcuDt5myWF4UxMXfSMG/SMXelFf/HpsJtNIIMGQpfeDncgVxW/p8+y1eKDBVapdm16GPQ9gr/3K/3PuZ+zikUCjg7OyMvL6/Cv/E1bsTpeU5OTmjWrBmuX79eat2ff/6Jr776ChcuXMD27dvRuXNnuLm5YciQIRgzZgzy8/Nhb29fZrvW1tawtrYutVwul5vlSQMAcrnMrPtnTMydNMybdMydrooKoWe3K5nK3c6E8mro4Q2pfTPnc06fPtX43hcUFOCvv/6Cl5eXznJBEBAREYE1a9agXr16UKvVUKlUAKD9r1qtrvJ4iYiIqOaqcYXTjBkzcOLECaSlpeH06dMYMGAALCwsMGzYMJ3ttm7dCjc3N+17m4KDg5GQkIAzZ85g7dq1eOWVV+Dk5FQNPSAiIqKaqsbdqrt79y6GDRuGhw8fws3NDR07dsSZM2fg5uam3ebevXtYunQpTp8+rV32+uuvY/r06ejduzfc3d0RExNTHeETERFRDVbjCqfdu3dXuI2HhwfS0tJKLZ83bx7mzZtnhKiIiIioNqhxhRMREREZTvFlqwq30QgyqBW+KM4q/xOJli1VhgzNJNW4Z5yIiIiIqgsLJyIiIiKRWDgRERERicRnnIiIqErYNA0zWFtF134yWFtE+uCIExEREZFILJyIiIiIRGLhRERERCQSCyciIiIikVg4EREREYnEwomIiIhIJBZORERERCKxcCIiIiISiYUTERERkUgsnIiIiIhEYuFEREREJBK/q46oHMWXrSrcRiPIoFb4ojjrDuQyodxtLVuqDBUaERFVA444EREREYnEwomIiIhIJBZORERERCKxcCIiIiISiYUTERERkUgsnIiIiIhE4usIiIhqCbWlq0Hbsyh+YND2iGoCjjgRERERicTCiYiIiEgkFk5EREREItW4wkkQBMybNw9eXl6wtbVFjx49cO3aNe16pVKJd955Bw4ODmjWrBmOHj2qs/+qVaswefLkqg6biIiIzECNK5xWrlyJ9evX44svvkBycjLs7OzQs2dPFBUVAQCio6Nx7tw5JCUlYfz48Rg+fDgE4en3h928eRNbtmzB0qVLq7MLREREVEPVqE/VCYKAdevWYe7cuejXrx8AYNeuXfDw8MB3332HoUOHIjU1FeHh4WjZsiUaNWqEmTNn4sGDB3Bzc8PEiROxYsUKODg4VHgspVIJpVKpnVcoFAAAjUYDjUZjnA5Wo6f9Esyyb5WhEWSitimZKtyW+dXiOSed1NxpZBWfo/qQ6Xl8Qx7++b6b87Vq4F+bUXNnSnnThz5x16jC6ebNm8jMzESPHj20yxwdHREUFISkpCQMHToUgYGB+PLLL/H48WMcOnQIXl5ecHV1RWxsLGxsbDBgwABRx1q2bBkWLlxYannGgxwUKIsN1qcSHfpPMVhbSd+t15lX/xVU4T4aQYYHhR5Q292DXCaUu61F42Td9l/vrn+Q5bX/6zHR2xoyb0Dp3MEtvcJ9NBoNsi0UsHB2gFxewSBuVrb2x+rMG8BzTqd9EzrnjJq7u6mSYnyhZ85nMa79vMtgh05//thGvFaB6j3nDJk3wMi5M6G86SM/P1/0tjWqcMrMzAQAeHh46Cz38PDQrhszZgwuXryIV155Ba6urtizZw9ycnIwb948JCYmYu7cudi9ezcaN26M7du3w8fHp8xjzZkzBx9++KF2XqFQwNfXF16uzqJGrPT14GGuwdrydnPRmS/OulPhPiX/F+HlcKfCf4gtn2tfnV7xRacPi+faL48h8waUzp0YT/9PRQZvN+eK/zF+RnXmDQBu/fKVQY//LJ5z4lX19VqbSb1Wgeq/XqtbTf13TiyFtfhyyKQLp9jYWERERGjnf/zxxwr3sbKywoYNG3SWvffee5gyZQouXLiA7777Dr///jtWrlyJKVOmYO/evWW2Y21tDWtr61LL5XK53hecGEL5//bp5fn4KvqH9dntSiZ92hcMGXwZ7ZfHwIeW/LuVy2V6nxvVmTdj4zkn/djGzl1tJ+VaBcz7ehXLnP+d06ddky6cwsPDERT0v2HrkmeO7t27By8vL+3ye/fuoXXr1mW2cfz4cVy+fBlbt27FzJkzERYWBjs7OwwZMgRRUVFGjZ+IiMwD35JOJUy6cLK3t4e9vb12XhAEeHp64tixY9pCSaFQIDk5GRMnTiy1f1FRESIjIxEbGwsLCwuo1Wpt9atSqaBWq6ukH0RERGQeatRYoUwmw9SpU7FkyRLs27cPf/zxB9599114e3ujf//+pbZfvHgxwsLC0KZNGwBAcHAw4uPjcfHiRURFRSE4OLiKe0BEREQ1mUmPOJVl1qxZKCwsxPjx45Gbm4uOHTvi4MGDsLGx0dnu0qVL2LNnD1JSUrTLBg8ejMTERHTq1AnNmzdHXFxcFUdPRERENVmNK5xkMhkWLVqERYsWlbtdq1atdN4oDjx9+Gvjxo3YuHGjMUMkIiIiM1XjCiciIj6oS0TVpUY940RERERUnVg4EREREYnEW3VUoxVd+6m6QyAiolqEI05EREREIrFwIiIiIhKJt+qIiPTA28NEtRtHnIiIiIhEYuFEREREJBJv1RFVE77EkYio5uGIExEREZFILJyIiIiIRGLhRERERCQSCyciIiIikfhwOBERERmFOX4IhiNORERERCKxcCIiIiISiYUTERERkUgsnIiIiIhEYuFEREREJBILJyIiIiKRWDgRERERicT3OBGRwVm2VFW4jUajgUVWNizdXCCX8//hiKhmYOFERGRCWHQSmTZecUREREQiccSpFjD2/8Ga4yv1iYiIylLjRpxGjx4NmUymM4WGhmrXK5VKvPPOO3BwcECzZs1w9OhRnf1XrVqFyZMnV3XYREREZAZEjTgpFAq9G3ZwcNB7H7FCQ0OxY8cO7by1tbX25+joaJw7dw5JSUk4cOAAhg8fjnv37kEmk+HmzZvYsmULzp49a7TYiIiIyHyJKpycnJwgk8lENyqTyXD16lU0atRIcmDlsba2hqenZ5nrUlNTER4ejpYtW6JRo0aYOXMmHjx4ADc3N0ycOBErVqwwalFHRERE5kv0M07//ve/4eLiUuF2giAgLCysUkFVJDExEe7u7nB2dka3bt2wZMkS1K9fHwAQGBiIL7/8Eo8fP8ahQ4fg5eUFV1dXxMbGwsbGBgMGDBB1DKVSCaVSqZ0vGXXTaDTQaDQG75MedWmFpMT3tF+CUfpm7pg7aZg36Zg7aZg36cw9d/r0S1Th1KBBA3Tu3FlbnFSkUaNGsLKyEh2EPkJDQzFw4EA0bNgQf/31Fz766CP06tULSUlJsLCwwJgxY3Dx4kW88sorcHV1xZ49e5CTk4N58+YhMTERc+fOxe7du9G4cWNs374dPj4+ZR5n2bJlWLhwYanlGQ9yUKAsNni/XOs7Gayt9KxsvffRaDTIylEAEPjxZj0xd9Iwb9Ixd9Iwb9KZe+7y8/NFbysTBEEwYiyVEhsbi4iICO38gQMH0KlTJ51tbty4gcaNG+Po0aPo3r17me289957aN26NRo2bIiPPvoIycnJWLlyJS5duoS9e/eWuU9ZI06+vr7Iyckxyq0+uxZ9DNZW4Z/79d5Ho9EgPSsH3m7OZnlRGBNzJw3zJh1zJw3zJp25506hUMDZ2Rl5eXkV/o036dcRhIeHIygoSDtf1uhQo0aN4OrqiuvXr5dZOB0/fhyXL1/G1q1bMXPmTISFhcHOzg5DhgxBVFTUC49tbW2t89B5CblcbpSTxpDlq9T45HKZ0fpn7pg7aZg36Zg7aZg36cw5d/r0SXLvMzIyMHjwYLi5ucHFxQV9+/bFjRs3pDZXJnt7ezRp0kQ72draltrm7t27ePjwIby8vEqtKyoqQmRkJDZv3gwLCwuo1WqoVE/faaRSqaBWqw0aLxEREZk3yYXTmDFj0KpVK5w4cQIJCQnw8PDA8OHDDRlbKQUFBZg5cybOnDmDtLQ0HDt2DP369UOTJk3Qs2fPUtsvXrwYYWFhaNOmDQAgODgY8fHxuHjxIqKiohAcHGzUeImIiMi8iL5V98EHH+DTTz+FnZ0dAOD69euIj4/XjgJ98MEH6Ny5s3Gi/P8sLCxw8eJFxMTEIDc3F97e3ggJCcHixYtL3Va7dOkS9uzZg5SUFO2ywYMHIzExEZ06dULz5s0RFxdn1HiJiIjIvIgunF566SW0a9cOK1euRHh4ON5++20EBQUhLCwMKpUK8fHxGDFihDFjha2tLQ4dOiRq21atWuHatWs6y+RyOTZu3IiNGzcaIzwiIiIyc6ILp5kzZ2Lw4MGYNGkSdu7cic8//xxBQUFITEyEWq3GypUrMXjwYGPGSkRERFSt9PpUXcOGDXHgwAHExsbizTffxAcffIDVq1fr9VZxIiIioppK74fDHz58iBEjRuC3337DhQsX0KFDB1y8eNEYsRERERGZFNGF07Fjx+Dh4QE3Nze89NJL+PPPP7F9+3YsW7YMw4YNw6xZs/D48WNjxkpERERUrUQXTpGRkZg1axYePXqEqKgoTJ06FQDQtWtXnD9/HlZWVmjdurWRwiQiIiKqfqILp4yMDPTu3Rs2NjYIDQ1FVlaWdp21tTWWLl2K+Ph4owRJREREZApEPxweHh6OwYMHIzw8HKdOnUJYWFipbVq2bGnQ4IiIiIhMiegRp23btiEiIgJ5eXkYOXIk1q1bZ8SwiIiIiEyP6BGnOnXqYPLkycaMhYiIiMikiRpx2rdvn/bLccX46aef+Ak7IiIiMjuiCqcBAwYgNzdXdKNDhw5FRkaG1JiIiIiITJKoW3WCIGD06NGlvkj3RYqKiioVFBEREZEpElU4jRo1Sq9GR4wYAQcHB0kBEREREZkqUYXTjh07jB0HERERkcnT+7vqiIiIiGorFk5EREREIrFwIiIiIhKJhRMRERGRSCyciIiIiEQS9am69evXi25wypQpkoMhIiIiMmWiCqe1a9eKakwmk7FwIiIiIrMlqnC6efOmseMgIiIiMnl8xomIiIhIJFEjTh9++KHoBtesWSM5GCIiIiJTJqpwunDhgqjGZDJZpYIhIiIiMmWiCqfjx48bOw4iIiIik8dnnIiIiIhEElU4DRw4EAqFQvtzeVNlxMfHIyQkBPXr14dMJkNKSkqpbYqKihAZGYn69eujXr16GDRoEO7du6ddn52djb59+6JevXpo06ZNqduMkZGR+OyzzyoVJxEREdVOogonR0dH7fNLjo6O5U6VUVhYiI4dO2LFihUv3GbatGn44Ycf8M033+DEiRNIT0/XKdiWLl2K/Px8nD9/Hl26dMG4ceO0686cOYPk5GRMnTq1UnESERFR7STqGacdO3aU+bOhvfPOOwCAtLS0Mtfn5eVh27ZtiIuLQ7du3bTxvPzyyzhz5gzeeOMNpKamYujQoWjWrBnGjx+P6OhoAIBKpcKECROwdetWWFhYGK0PREREZL5EFU7P+te//oVhw4aVuW7mzJlYtWpVpYN6kXPnzkGlUqFHjx7aZS1atICfnx+SkpLwxhtvIDAwEAkJCfj73/+OQ4cOISAgAACwcuVKdOnSBe3btxd1LKVSCaVSqZ0vuVWp0Wig0WgM2KunDPmBRCnxPe2XYJS+mTvmThrmTTrmThrmTTpzz50+/dK7cJo4cSKcnJzQq1cvneXTpk3D7t27jVo4ZWZmok6dOnByctJZ7uHhgczMTADAP/7xD0ycOBGNGzeGv78/tm3bhmvXriEmJgZJSUmYMGECDh8+jPbt22PLli0vvL24bNkyLFy4sNTyjAc5KFAWG7xvrvWdKtxGrPSsbL330Wg0yMpRABAgl/MzA/pg7qRh3qRj7qRh3qQz99zl5+eL3lbvwik2NhbDhg3D/v370bFjRwDA5MmTER8fr9drC2JjYxEREaGdP3DgADp16qRvOKU4OjoiLi5OZ1m3bt2watUqxMbG4saNG7hy5QrGjRuHRYsWvfBB8Tlz5ui8+FOhUMDX1xders5wcHCodJzPe/Aw12Btebu56L3P02pbBm83Z7O8KIyJuZOGeZOOuZOGeZPO3HOnsBZfDuldOPXu3RsbN25EeHg4jhw5gm3btuH777/H8ePH0axZM9HthIeHIygoSDvv4+NT4T6enp548uQJcnNzdUad7t27B09PzzL32bFjB5ycnNCvXz8MHDgQ/fv3h5WVFd566y3MmzfvhceytraGtbV1qeVyudwoJ40gGK4tqfHJ5TKj9c/cMXfSMG/SMXfSMG/SmXPu9OmT3oUTAAwfPhy5ubkIDg6Gm5sbTpw4gSZNmujVhr29Pezt7fXap127drCyssKxY8cwaNAgAMCVK1dw+/ZtdOjQodT2WVlZWLRoEU6dOgUAUKvVUKlUAJ4+LK5Wq/U6PhEREdVulfquOjc3N7Rt2xYbN27ULqvMd9VlZ2fj9u3bSE9PB/C0KAKejjR5enrC0dERY8eOxYcffggXFxc4ODhg8uTJ6NChA954441S7U2dOhXTp0/XjmYFBwfjyy+/REhICKKjoxEcHCw5ViIiIqp9KvVddU2aNIFCodCur+x31e3btw/vvfeedn7o0KEAgPnz52PBggUAgLVr10Iul2PQoEFQKpXo2bOnTuFW4tChQ7h+/Tq+/PJL7bL3338fZ8+eRVBQEF5//XXMnz+/UvESERFR7SITBEM+XWO+FAoFHB0dkZeXZ5SHw22ahhmsraJrP+m9j0ajQXpWNrzdXMzy/rUxMXfSMG/SMXfSMG/SmXvu9PkbX+ne37p1C//5z3/M9t0ORERERCVEF07bt28v9fzS+PHj0ahRI7z66qto1aoV7ty5Y/AAiYiIiEyF6MIpOjoazs7O2vmDBw9ix44d2LVrF3777Tc4OTmV+cJIIiIiInMh+nUE165d0/m6ku+//x79+vXDiBEjAACffvqpzoPdREREROZG9IjT48ePdR6YOn36NDp37qydb9SokfZrT4iIiIjMkejCqUGDBjh37hwA4MGDB7h8+bLOe5AyMzNf+L1vREREROZA9K26UaNGITIyEpcvX0ZCQgJatGiBdu3aadefPn0arVq1MkqQRERERKZAdOE0a9YsPHr0CPHx8fD09MQ333yjs/6XX37BsGHDDB4gERERkakQXTjJ5XIsWrQIixYtKnP984UUERERkbkxv9d/EhERERkJCyciIiIikVg4EREREYnEwomIiIhIJL0Lp0WLFuHRo0ellj9+/PiFD44TERERmQO9C6eFCxeioKCg1PJHjx7xu+qIiIjIrOldOAmCAJlMVmr577//DhcXF4MERURERGSKRL/HydnZGTKZDDKZDM2aNdMpntRqNQoKCjBhwgSjBElERERkCkQXTuvWrYMgCBgzZgwWLlyo8710derUgb+/Pzp06GCUIImIiIhMgV7fVQcADRs2RHBwMCwtRe9KREREZBb0fsbJ3t4eqamp2vnvv/8e/fv3x0cffYQnT54YNDgiIiIiU6J34RQREYGrV68CAG7cuIG3334bdevWxTfffINZs2YZPEAiIiIiU6F34XT16lW0bt0awNMv9n3zzTcRFxeHnTt3Yu/evYaOj4iIiMhkSHodgUajAQAcPXoUYWFhAABfX188ePDAsNERERERmRC9C6f27dtjyZIl+PLLL3HixAn07t0bAHDz5k14eHgYPEAiIiIiU6F34bRu3TqcP38e77//Pj7++GM0adIEAPDvf/8b//d//2fwAImIiIhMhd7vFAgICMAff/xRavmqVatgYWFhkKCIiIiITJHBXsZkY2NjqKaIiIiITJLet+rUajVWr16N119/HZ6ennBxcdGZKiM+Ph4hISGoX78+ZDIZUlJSSm3TpUsX7Ve/lEzPftVLdnY2+vbti3r16qFNmza4cOGCzv6RkZH47LPPKhUnERER1U56F04LFy7EmjVr8PbbbyMvLw8ffvghBg4cCLlcjgULFlQqmMLCQnTs2BErVqwod7tx48YhIyNDO61cuVK7bunSpcjPz8f58+fRpUsXjBs3TrvuzJkzSE5OxtSpUysVJxEREdVOet+qi42NxZYtW9C7d28sWLAAw4YNQ+PGjREQEIAzZ85gypQpkoN55513AABpaWnlble3bl14enqWuS41NRVDhw5Fs2bNMH78eERHRwMAVCoVJkyYgK1bt/JZLCIiIpJE78IpMzMTr776KgCgXr16yMvLAwD06dMHn3zyiWGje4HY2Fh89dVX8PT0RN++ffHJJ5+gbt26AIDAwEAkJCTg73//Ow4dOoSAgAAAwMqVK9GlSxe0b99e1DGUSiWUSqV2XqFQAAA0Go32PVaGJJMZri0p8T3tl2CUvpk75k4a5k065k4a5k06c8+dPv3Su3B66aWXkJGRAT8/PzRu3BiHDx9G27Zt8dtvv8Ha2lrf5vQ2fPhwNGjQAN7e3rh48SJmz56NK1euID4+HgDwj3/8AxMnTkTjxo3h7++Pbdu24dq1a4iJiUFSUhImTJiAw4cPo3379tiyZQscHR3LPM6yZcuwcOHCUsszHuSgQFls8H651ncyWFvpWdl676PRaJCVowAgQC7X+w5urcbcScO8ScfcScO8SWfuucvPzxe9rUwQBEGfxv/xj3/AwcEBH330Eb7++muMHDkS/v7+uH37NqZNm4bly5eLaic2NhYRERHa+QMHDqBTp04Ant6qa9iwIS5cuKD9epcXSUhIQPfu3XH9+nU0bty4zG26deuGDz74ALdu3cL+/fvx448/Yty4cahfv/4LHxQva8TJ19cXOTk5cHBwENVHfdi16GOwtgr/3K/3PhqNBulZOfB2czbLi8KYmDtpmDfpmDtpmDfpzD13CoUCzs7OyMvLq/BvvN4jTs8WRm+//TYaNGiA06dPo2nTpujbt6/odsLDwxEUFKSd9/Hx0TcUANC28aLCaceOHXByckK/fv0wcOBA9O/fH1ZWVnjrrbcwb968F7ZrbW1d5giaXC43ykmjX/laPqnxyeUyo/XP3DF30jBv0jF30jBv0plz7vTpU6Xf4/TGG2/gjTfe0Hs/e3t72NvbV/bw2lcWeHl5lVqXlZWFRYsW4dSpUwCevkpBpVIBePqwuFqtrvTxiYiIqPbQu3BatmwZPDw8MGbMGJ3l27dvR1ZWFmbPni05mOzsbNy+fRvp6ekAgCtXrgAAPD094enpib/++gtxcXEICwtD/fr1cfHiRUybNg2dO3fWPgT+rKlTp2L69Ona0azg4GB8+eWXCAkJQXR0NIKDgyXHSkRERLWP3uNtmzdvRosWLUotb9myJb744otKBbNv3z60adNG+8XBQ4cORZs2bbTt1qlTB0ePHkVISAhatGiB6dOnY9CgQfjhhx9KtXXo0CFcv34dkyZN0i57//330ahRIwQFBeHJkyeYP39+peIlIiKi2kXS6wjKui3m5uaGjIyMSgUzevRojB49+oXrfX19ceLECVFt9ezZEz179tRZVrduXezZs6cyIRIREVEtpveIk6+vL3755ZdSy3/55Rd4e3sbJCgiIiIiU6T3iNO4ceMwdepUqFQqdOvWDQBw7NgxzJo1C9OnTzd4gERERESmQu/CaebMmXj48CEmTZqEJ0+eAABsbGwwe/ZszJkzx+ABEhEREZkKvQsnmUyGFStW4JNPPkFqaipsbW3RtGnTKnlrOBEREVF1kvwWq8zMTGRnZ6Nx48awtraGni8gJyIiIqpx9C6cHj58iO7du6NZs2YICwvTfpJu7NixfMaJiIiIzJrehdO0adNgZWWF27dvo27dutrlb7/9Ng4ePGjQ4IiIiIhMid7POB0+fBiHDh3CSy+9pLO8adOmuHXrlsECIyIiIjI1eo84FRYW6ow0lcjOzuYD4kRERGTW9C6cOnXqhF27dmnnZTIZNBoNVq5cia5duxo0OCIiIiJTovetupUrV6J79+44e/Ysnjx5glmzZuHy5cvIzs4u843iREREROZC7xGnVq1a4erVq+jYsSP69euHwsJCDBw4EBcuXEDjxo2NESMRERGRSdBrxEmlUiE0NBRffPEFPv74Y2PFRERERGSS9BpxsrKywsWLF40VCxEREZFJ0/tW3ciRI7Ft2zZjxEJERERk0vR+OLy4uBjbt2/H0aNH0a5dO9jZ2emsX7NmjcGCIyIiIjIlehdOly5dQtu2bQEAV69e1Vknk8kMExURERGRCdK7cDp+/Lgx4iAiIiIyeXo/4/Ssu3fv4u7du4aKhYiIiMik6V04aTQaLFq0CI6OjmjQoAEaNGgAJycnLF68GBqNxhgxEhEREZkEvW/Vffzxx9i2bRuWL1+O4OBgAMCpU6ewYMECFBUVYenSpQYPkoiIiMgU6F04xcTEYOvWrQgPD9cuCwgIgI+PDyZNmsTCiYiIiMyW3rfqsrOz0aJFi1LLW7RogezsbIMERURERGSK9C6cAgMDERUVVWp5VFQUAgMDDRIUERERkSnS+1bdypUr0bt3bxw9ehQdOnQAACQlJeHOnTv46aefDB4gERERkanQe8TpzTffxNWrVzFgwADk5uYiNzcXAwcOxJUrV9CpUydjxEhERERkEkSPON24cQMNGzaETCaDt7c3HwInIiKiWkf0iFPTpk2RlZWlnX/77bdx7949gwWiUqkwe/ZsvPrqq7Czs4O3tzfeffddpKen62yXnZ2NESNGwMHBAU5OThg7diwKCgq069PS0tC5c2fY2dmhc+fOSEtL09m/T58+2Lt3r8HiJiIiotpDdOEkCILO/E8//YTCwkKDBfLo0SOcP38en3zyCc6fP4/4+HhcuXJF57UHADBixAhcvnwZR44cwf79+3Hy5EmMHz9eu3769Onw8fFBSkoKvLy8MGPGDO26r7/+GnK5HIMGDTJY3ERERFR76P1wuLE4OjriyJEjOsuioqLw+uuv4/bt2/Dz80NqaioOHjyI3377De3btwcAfP755wgLC8Pq1avh7e2N1NRUrFmzBk2bNsXo0aO1hVNubi7mzp2LhISEKu8bERERmQfRhZNMJoNMJiu1zJjy8vIgk8ng5OQE4Omn95ycnLRFEwD06NEDcrkcycnJGDBgAAIDA3H06FGEhITg8OHDCAgIAADMnDkTkZGR8PX1FXVspVIJpVKpnVcoFACefuWMMb5axpCplBLf034J/NocCZg7aZg36Zg7aZg36cw9d/r0S3ThJAgCRo8eDWtrawBAUVERJkyYADs7O53t4uPjRR+8PEVFRZg9ezaGDRsGBwcHAEBmZibc3d11trO0tISLiwsyMzMBAKtXr0ZERAT8/f0REBCAzZs34+TJk0hJScGKFSswZMgQnD17FiEhIVi/fj3q1KlT5vGXLVuGhQsXllqe8SAHBcpig/TxWa71nQzWVnqW/i8i1Wg0yMpRABAgl1fqu59rHeZOGuZNOuZOGuZNOnPPXX5+vuhtRRdOo0aN0pkfOXKk+IjKEBsbi4iICO38gQMHtK8zUKlUGDJkCARBwKZNm/Rq18fHB/v379fOK5VK9OzZEzExMViyZAns7e1x5coVhIaGYvPmzZg8eXKZ7cyZMwcffvihdl6hUMDX1xders7aQs6QHjzMNVhb3m4ueu/ztNqWwdvN2SwvCmNi7qRh3qRj7qRh3qQz99wprMU/uSR6yx07dkgK5kXCw8MRFBSknffx8QHwv6Lp1q1bSEhI0ClSPD09cf/+fZ12iouLkZ2dDU9PzzKP8+mnnyIkJATt2rXDuHHjsGTJElhZWWHgwIFISEh4YeFkbW2tHV17llwuN8pJ89yz95UiNT65XGa0/pk75k4a5k065k4a5k06c86dPn2qtofD7e3tYW9vr7OspGi6du0ajh8/jvr16+us79ChA3Jzc3Hu3Dm0a9cOAJCQkACNRqNThJVITU1FXFwcUlJSAABqtRoqlUp7LLVabYSeERERkbkymbJRpVJh8ODBOHv2LGJjY6FWq5GZmYnMzEw8efIEAPDyyy8jNDQU48aNw6+//opffvkF77//PoYOHQpvb2+d9gRBwPjx47F27Vrtc1jBwcHYsmULUlNTsWvXLgQHB1d5P4mIiKjmMpnC6b///S/27duHu3fvonXr1vDy8tJOp0+f1m4XGxuLFi1aoHv37ggLC0PHjh0RHR1dqr3o6Gh4eHigT58+2mULFixAUVERgoKC0KRJE0RGRlZJ34iIiMg8mMx7nPz9/Uu9ZLMsLi4uiIuLq3C7iIgInYfPAcDd3R1Hjx6VHCMRERHVbiYz4kRERERk6lg4EREREYnEwomIiIhIJBZORERERCKxcCIiIiISiYUTERERkUgsnIiIiIhEYuFEREREJBILJyIiIiKRWDgRERERicTCiYiIiEgkFk5EREREIrFwIiIiIhKJhRMRERGRSCyciIiIiERi4UREREQkEgsnIiIiIpFYOBERERGJxMKJiIiISCQWTkREREQisXAiIiIiEomFExEREZFILJyIiIiIRGLhRERERCQSCyciIiIikVg4EREREYnEwomIiIhIJJMpnFQqFWbPno1XX30VdnZ28Pb2xrvvvov09HSd7fz9/SGTyXSm5cuXa9enpaWhc+fOsLOzQ+fOnZGWlqazf58+fbB3796q6BIRERGZGZMpnB49eoTz58/jk08+wfnz5xEfH48rV64gPDy81LaLFi1CRkaGdpo8ebJ23fTp0+Hj44OUlBR4eXlhxowZ2nVff/015HI5Bg0aVCV9IiIiIvNiWd0BlHB0dMSRI0d0lkVFReH111/H7du34efnp11ub28PT0/PMttJTU3FmjVr0LRpU4wePVpbOOXm5mLu3LlISEgwXieIiIjIrJlM4VSWvLw8yGQyODk56Sxfvnw5Fi9eDD8/PwwfPhzTpk2DpeXTrgQGBuLo0aMICQnB4cOHERAQAACYOXMmIiMj4evrK+rYSqUSSqVSO69QKAAAGo0GGo3GAL3TJZMZri0p8T3tl2CUvpk75k4a5k065k4a5k06c8+dPv0y2cKpqKgIs2fPxrBhw+Dg4KBdPmXKFLRt2xYuLi44ffo05syZg4yMDKxZswYAsHr1akRERMDf3x8BAQHYvHkzTp48iZSUFKxYsQJDhgzB2bNnERISgvXr16NOnTplHn/ZsmVYuHBhqeUZD3JQoCw2eH9d6zsZrK30rGy999FoNMjKUQAQIJebzB3cGoG5k4Z5k465k6a686bRaKBRq6v8uIag0WiQoyhAsepJjTzn5BYW5cadn58vui2ZIAiCIYLSV2xsLCIiIrTzBw4cQKdOnQA8fVB80KBBuHv3LhITE3UKp+dt374dERERKCgogLW1dan1SqUS7dq1Q0xMDGJjY5GXl4cvvvgCoaGh6N+/v87zUc/v9/yIk6+vL3JycsqNRyq7Fn0M1lbhn/v13kej0SA9Kwfebs418qKoTsydNMybdMydNNWVN0EQcO/ePeTm5lbZMY1BrdHAogafb05OTvDw8ICsjFs8CoUCzs7OyMvLq/BvfLWNOIWHhyMoKEg77+PjA+Bp0TRkyBDcunULCQkJFXYgKCgIxcXFSEtLQ/PmzUut//TTTxESEoJ27dph3LhxWLJkCaysrDBw4EAkJCS8sHCytrYusxCTy+VGueAMWb5KjU8ulxmtf+aOuZOGeZOOuZOmOvKWkZGBvLw8eHh4oG7dumX+4TZ1giBAVVwMK0vLGhe/IAh49OgR7t+/D5lMBi8vr1Lb6HM+VFvhZG9vD3t7e51lJUXTtWvXcPz4cdSvX7/CdlJSUiCXy+Hu7l5qXWpqKuLi4pCSkgIAUKvVUKlU2mOpa+iQKRER1QxqtRq5ublwd3cX9TfNVAmCAIsaWjgBgK2tLQDg/v37cHd3h4WFheS2TOYZJ5VKhcGDB+P8+fPYv38/1Go1MjMzAQAuLi6oU6cOkpKSkJycjK5du8Le3h5JSUmYNm0aRo4cCWdnZ532BEHA+PHjsXbtWtjZ2QEAgoODsWXLFjRr1gy7du3CsGHDqryfRERUe5T8z3rdunWrORIq+R2oVKpKFU4mM8b73//+F/v27cPdu3fRunVreHl5aafTp08DeHr7bPfu3XjzzTfRsmVLLF26FNOmTUN0dHSp9qKjo+Hh4YE+ff737NCCBQtQVFSEoKAgNGnSBJGRkVXWPyIiqr1q4iiNuTHU78BkRpz8/f1R0XPqbdu2xZkzZ0S1FxERofPwOQC4u7vj6NGjkmMkIiKi2s1kRpyIiIiITJ3JjDgRERHVJjZNw6r0eEXXfqrS44k1evRo5Obm4rvvvqvuUEThiBMRERGVsmDBAshkMshkT1/hYF2nDl5++WWDH+ef//wndu7cafB2jYUjTkRERFSmli1b4ujRo9r3ONna2Bj8GI6OjgZv05g44kRERERlsrS0hKenp3ZydXV94bZpaWmQyWTYs2cPOnXqBFtbW7z22mu4evUqfvvtN7Rv3x716tVDr169kJWVpd1v9OjR6N+/v3a+S5cumDJlCmbNmgUXFxd4enpiwYIFRuylflg4ERERUZmuXbsGb29vNG7cGKPefRe3b9+ucJ/58+dj7ty5OH/+PCwtLTF8+HDMmjUL//znP/Hzzz/j+vXrmDdvXrltxMTEwM7ODsnJyVi5ciUWLVqEI0eOGKpblcJbdURERFRKUFAQdu7ciebNmyM9PR0LFy5E586dcenSpVLf/PGsGTNmoGfPngCADz74AMOGDcOxY8cQHBwMABg7dmyFzzQFBARg/vz5AICmTZsiKioKx44dw9/+9jfDdK4SWDgRERFRKb169dL+/Oqrr6Jtu3Zo2qQJ9uzZg99++w1fffWVdn1BQYH254CAAO3PHh4e2v2fXXb//v1yj/1sGwDg5eVV4T5VhYUTERERVcjJyQnNmjXD9evXsWjRIsyYMaPM7aysrLQ/l7yt+/llGo2m3GM9u73YfaoKCyciIiKqUEFBAf766y+88847cHd3h7u7e3WHVC34cDgRERGVMmPGDJw4cQJpaWk4ffo03nrrLVhYWGDYsGHVHVq14ogTERFRNTDVN3mXuHv3LoYNG4aHDx/Czc0N//d//4ekpCS4ublVd2jVSiZU9M26BABQKBRwdHREXl4eHBwcDN6+IV+9L+Vi1Gg0SM/KhrebC+RyDkTqg7mThnmTjrmTpjryVlRUhJs3b6Jhw4awMcLLI6tKyQswrSwttc8t1TTl/S70+RvPK46IiIhIJBZORERERCKxcCIiIiISiYUTERERkUgsnIiIiIhEYuFEREREJBILJyIiIiKRWDgRERERicTCiYiIiEgkfuUKERFRNSi+bFWlx7NsqarS4xlSly5d0Lp1a6xbt666Q+GIExEREZV28uRJ9O3bF97e3pDL5fj+++911guCgHnz5sHLywu2trbo0aMHrl27ZpRY4uPjsXjxYqO0rS8WTkRERFRKYWEhAgMDsWHDhjLXr1y5EuvXr8cXX3yB5ORk2NnZoWfPnigqKjJ4LC4uLrC3tzd4u1KwcCIiIqJSevXqhSVLlmDAgAGl1gmCgHXr1mHu3Lno168fAgICsGvXLqSnp+O77757YZuJiYmQyWQ4dOgQ2rRpA1tbW3Tr1g3379/HgQMH8PLLL8PBwQHDhw/Ho0ePtPt16dIFU6dO1c77+/vj008/xZgxY2Bvbw8/Pz9ER0cbsvsvxMKJiIiI9HLz5k1kZmaiR48e2mWOjo4ICgpCUlJShfsvWLAAUVFROH36NO7cuYMhQ4Zg3bp1iIuLw48//ojDhw/j888/L7eNzz77DO3bt8eFCxcwadIkTJw4EVeuXKl03ypiUoXTggUL0KJFC9jZ2cHZ2Rk9evRAcnKyzjbZ2dkYMWIEHBwc4OTkhLFjx6KgoEC7Pi0tDZ07d4adnR06d+6MtLQ0nf379OmDvXv3VkV3iIiIzFJmZiYAwMPDQ2e5h4eHdl15lixZguDgYLRp0wZjx47FiRMnsGnTJrRp0wadOnXC4MGDcfz48XLbCAsLw6RJk9CkSRPMnj0brq6uFe5jCCZVODVr1gxRUVH4448/cOrUKfj7+yMkJARZWVnabUaMGIHLly/jyJEj2L9/P06ePInx48dr10+fPh0+Pj5ISUmBl5cXZsyYoV339ddfQy6XY9CgQVXaLyIiotqmV69eqFevHurVq4eWLVvqrAsICND+7OHhgbp166JRo0Y6y+7fv19u+8+2IZPJ4OnpWeE+hmBSryMYPny4zvyaNWuwbds2XLx4Ed27d0dqaioOHjyI3377De3btwcAfP755wgLC8Pq1avh7e2N1NRUrFmzBk2bNsXo0aO1hVNubi7mzp2LhIQEUbEolUoolUrtvEKhAABoNBpoNBpDdFeHTGa4tqTE97RfglH6Zu6YO2mYN+mYO2mqI28ajQaCIGin6lTp4wv/a6dkpCkzMxOenp7aTe7du4fAwEAIgoAtW7bg8ePHAAArKyudHFhaWurEU7L+WSW5ezb+Z+efb0Mmk0GtVr+wnyX7l/V3XJ9zwqQKp2c9efIE0dHRcHR0RGBgIAAgKSkJTk5O2qIJAHr06AG5XI7k5GQMGDAAgYGBOHr0KEJCQnD48GFtRTpz5kxERkbC19dX1PGXLVuGhQsXllqe8SAHBcpiA/RQl2t9J4O1lZ6Vrfc+Go0GWTkKAALkcpMaiDR5zJ00zJt0zJ001ZG3YpUKao0GquJiWBTr/u2o6t+cqrhyf7vUGg2eqIohkwEv+frC09MTh48cQctWrQA8HWBITk7GuHHjoCouhvtzt/FUxcUoVqu1P5fEo/7/Rcuz8ZUUTSXLBEGA5pn5kv2enS8pil7UT1VxMdQaDe5n58HS6pHOuvz8fNF5MLnCaf/+/Rg6dCgePXoELy8vHDlyBK6urgCeVrbu7u4621taWsLFxUV7T3X16tWIiIiAv78/AgICsHnzZpw8eRIpKSlYsWIFhgwZgrNnzyIkJATr169HnTp1yoxjzpw5+PDDD7XzCoUCvr6+8HJ1hoODg8H7/eBhrsHa8nZz0Xufp9W2DN5uzvyHWE/MnTTMm3TMnTTVkbeioiI8UuTAytISVpa6f3LVVRLB/zx//IoUFBTg+vXr2vk7t2/jP5cvwcXFBX5+fvjggw+wfNkytGjeHA0bNsS8efPg7e2NQYMGvfBYlhYW2lhKtrH4/7+LZ/eRy+WQyWTaZTKZDPJn5kv2e3ZeJpNB/tyyZ6ktLWEhl8PdxRE2NjY66xTW4nNTbYVTbGwsIiIitPMHDhxAp06d0LVrV6SkpODBgwfYsmULhgwZguTk5FIF04v4+Phg//792nmlUomePXsiJiYGS5Ysgb29Pa5cuYLQ0FBs3rwZkydPLrMda2trWFtbl1oul8uNcsEZcgRXanxyucxo/TN3zJ00zJt0zJ00VZ23kgKgZHqWqb/J+9y5c+jatat2ftasmQCAUaNGYefOnZg9ezYePXqEiIgI5ObmomPHjjh48CBsbW1f2GZJDp7Nx/P/LW9ZefMvWvb8urJ+//qcDzKhmm665ufn4969e9p5Hx+fMpPdtGlTjBkzBnPmzMH27dsxffp05OTkaNcXFxfDxsYG33zzTZnvmpg/fz7y8/OxZs0atG3bFkuWLEFYWBg2bNiAhIQE0Z+wUygUcHR0RF5enlFGnGyahhmsraJrP+m9j0ajQXpWNrzdXPgPsZ6YO2mYN+mYO2mqI29FRUW4efMmGjZsWGqUoyYpuW1mZWn5wsLE1JX3u9Dnb3y1jTjZ29uLeguoRqPRPqTdoUMH5Obm4ty5c2jXrh0AICEhARqNBkFBQaX2TU1NRVxcHFJSUgAAarUaKtXTCl+lUkGtruqBUiIiIqrJTOZ/VQoLC/HRRx/hzJkzuHXrFs6dO4cxY8bgv//9L9566y0AwMsvv4zQ0FCMGzcOv/76K3755Re8//77GDp0KLy9vXXaEwQB48ePx9q1a2FnZwcACA4OxpYtW5Camopdu3YhODi4yvtJRERENZfJPBxuYWGBP//8EzExMXjw4AHq16+P1157DT///LPO+x9iY2Px/vvvo3v37tp3Mq1fv75Ue9HR0fDw8ECfPn20yxYsWIDhw4cjKCgIoaGhiIyMrJK+iSHl9hoRERFVLZMpnGxsbBAfH1/hdi4uLoiLi6twu4iICJ2HzwHA3d0dR48elRwjERER1W4mc6uOiIiIyNSxcCIiIiISiYUTERERkUgsnIiIiIhEYuFEREREJq1Lly6YOnVqdYcBwIQ+VUdERFSbqC1dq/R4FsUP9Nr+5MmTWLVqFc6dO4eMjAzs+eYbDB40SLt+9OjRiImJ0dmnZ8+eOHjwoEHifVZ8fDysrKwM3q4UHHEiIiKiUgoLCxEYGIgNGza8cJvQ0FBkZGRop3/9619GicXFxUXUt41UBRZOREREVEqvXr2wZMmSMr8HtoS1tTU8PT21k7Ozc7ltJiYmQiaT4dChQ2jTpg1sbW3RrVs33L9/HwcOHMDLL78MBwcHDB8+HI8ePdLu9/ytOn9/f3z66acYM2YM7O3t4efnh+jo6Er3WQwWTkRERCRJYmIi3N3d0bx5c0ycOBEPHz4Utd+CBQsQFRWF06dP486dOxgyZAjWrVuHuLg4/Pjjjzh8+DA+//zzctv47LPP0L59e1y4cAGTJk3CxIkTceXKFUN0q1wsnIiIiEhvoaGh2LVrF44dO4YVK1bgxIkT6NWrF9RqdYX7LlmyBMHBwWjTpg3Gjh2LEydOYNOmTWjTpg06deqEwYMH4/jx4+W2ERYWhkmTJqFJkyaYPXs2XF1dK9zHEPhwOBEREelt6NCh2p9fffVVBAQEoHHjxkhMTET37t3Rq1cv/PzzzwCABg0a4PLly9rtAwICtD97eHigbt26aNSokc6yX3/9tdzjP9uGTCaDp6cn7t+/X+l+VYSFExEREVVao0aN4OrqiuvXr6N79+7YunUrHj9+DAClPhH37LxMJiu1XiaTQaPRlHs8KfsYAgsnIiIiqrS7d+/i4cOH8PLyAgD4+PhUc0TGwcKJiIiISikoKMD169e182lpaUhJSUH9+vXh4uKChQsXYtCgQfD09MRff/2FWbNmoUmTJujZs2c1Rm18LJyIiIiolLNnz6Jr167a+VkzZwIARo0ahU2bNuHixYuIiYlBbm4uvL29ERISgsWLF8Pa2rq6Qq4SMkEQhOoOoiZQKBRwdHREXl4eHBwcqjscg9NoNEjPyoa3mwvkcn7YUh/MnTTMm3TMnTTVkbeioiLcvHkTDRs2hI2NTZUc0xgEQYCquBhWlpaQyWTVHY4k5f0u9PkbzyuOiIiISCQWTkREREQisXAiIiIiEomFExEREZFILJyIiIiIRGLhREREZGRV8UZrKp+hfgd8jxMREZGR1KlTB3K5HOnp6XBzc0OdOnVq5Mf5S15HoK6BryMQBAFPnjxBVlYW5HI56tSpU6n2WDgREREZiVwuR8OGDZGRkYH09PTqDkcyQRCg1mhgIZfXuMKpRN26deHn51fpd3ixcCIiIjKiOnXqwM/PD8XFxVCr1dUdjiQajQb3s/Pg7uJYI1+6amFhAUsDjZaxcCIiIjIymUwGKysrWFlZVXcokmg0GlhaPYKNjU2NLJwMyaR6v2DBArRo0QJ2dnZwdnZGjx49kJycrLONv78/ZDKZzrR8+XLt+rS0NHTu3Bl2dnbo3Lkz0tLSdPbv06cP9u7dWxXdISIiIjNjUoVTs2bNEBUVhT/++AOnTp2Cv78/QkJCkJWVpbPdokWLkJGRoZ0mT56sXTd9+nT4+PggJSUFXl5emDFjhnbd119/DblcjkGDBlVZn4iIiMh8mFThNHz4cPTo0QONGjVCy5YtsWbNGigUCly8eFFnO3t7e3h6emonOzs77brU1FSMGjUKTZs2xejRo5GamgoAyM3Nxdy5c7Fhw4Yq7RMRERGZD5N9xunJkyeIjo6Go6MjAgMDddYtX74cixcvhp+fH4YPH45p06bB0vJpVwIDA3H06FGEhITg8OHDCAgIAADMnDkTkZGR8PX1FXV8pVIJpVKpnc/LywPwtAAzx/dxaDQa5OUpUNdKXuvvX+uLuZOGeZOOuZOGeZPO3HOnUCgAPP30YIUEE/PDDz8IdnZ2gkwmE7y9vYVff/1VZ/1nn30mHD9+XPj999+FTZs2CU5OTsK0adO06+/evSv07t1b8PX1FXr37i3cvXtXOHHihNC+fXvh4cOHwltvvSU0bNhQiIiIEJRK5QvjmD9/vgCAEydOnDhx4lRLpjt37lRYp8gEQUx5ZXixsbGIiIjQzh84cACdOnVCYWEhMjIy8ODBA2zZsgUJCQlITk6Gu7t7me1s374dERERKCgogLW1dan1SqUS7dq1Q0xMDGJjY5GXl4cvvvgCoaGh6N+/v87zUc/v9+yIk0ajQXZ2NurXr19j32FRHoVCAV9fX9y5cwcODg7VHU6NwtxJw7xJx9xJw7xJZ+65EwQB+fn58Pb2rnBErdoKp/z8fNy7d0877+PjA1tb21LbNW3aFGPGjMGcOXPKbOfy5cto1aoV/vzzTzRv3rzU+vnz5yM/Px9r1qxB27ZtsWTJEoSFhWHDhg1ISEjgJ+z+P4VCAUdHR+Tl5ZnlRWFMzJ00zJt0zJ00zJt0zN3/VNszTvb29rC3t69wO41GozPy87yUlBTI5fIyR6RSU1MRFxeHlJQUAIBarYZKpQIAqFSqGvsiMiIiIqoeJvNweGFhIZYuXYrw8HB4eXnhwYMH2LBhA/773//irbfeAgAkJSUhOTkZXbt2hb29PZKSkjBt2jSMHDkSzs7OOu0JgoDx48dj7dq12k/dBQcHY8uWLWjWrBl27dqFYcOGVXk/iYiIqOYymUfjLSws8Oeff2LQoEFo1qwZ+vbti4cPH+Lnn39Gy5YtAQDW1tbYvXs33nzzTbRs2RJLly7FtGnTEB0dXaq96OhoeHh4oE+fPtplCxYsQFFREYKCgtCkSRNERkZWWf9MnbW1NebPn1/mc2JUPuZOGuZNOuZOGuZNOubuf6rtGSciIiKimsZkRpyIiIiITB0LJyIiIiKRWDgRERERicTCiYiIiEgkFk5EREREIrFwqgWysrIwceJE+Pn5wdraGp6enujZsyd++eWXcvfLzs7G5MmT0bx5c9ja2sLPzw9TpkzRfuGxuRo9ejRkMhkmTJhQal1kZCRkMhlGjx5dYTvLli3Da6+9Bnt7e7i7u6N///64cuWKESI2PaNHj0b//v312qe2nm/PknqtAkBERAQaN24MW1tbuLm5oV+/fvjzzz+rIOrqZajrddOmTQgICICDgwMcHBzQoUMHHDhwwAgRmxYp1ypQe883gIVTrTBo0CBcuHABMTExuHr1Kvbt24cuXbrg4cOH5e6Xnp6O9PR0rF69GpcuXcLOnTtx8OBBjB07tooirz6+vr7YvXs3Hj9+rF1WVFSEuLg4+Pn5iWrjxIkTiIyMxJkzZ3DkyBGoVCqEhISgsLDQWGHXaLX5fCsh9VoFgHbt2mHHjh1ITU3FoUOHIAgCQkJCasU3JBjien3ppZewfPlynDt3DmfPnkW3bt3Qr18/XL582Vhh12i1+XxDhV8DTDVaTk6OAEBITEw0SHt79uwR6tSpI6hUKoO0Z4pGjRol9OvXT2jVqpXw1VdfaZfHxsYKAQEBQr9+/YRRo0bp3e79+/cFAMKJEycMGK1pKslhZdWG862Eoa/V33//XQAgXL9+3SDtmSpjXa+CIAjOzs7C1q1bDRSpaTLUtVpbzjdBEASOOJm5evXqoV69evjuu+/K/c4/sUq+4NHS0mS+rcdoxowZgx07dmjnt2/fjvfee09yeyW3nFxcXCodW21Rm843Q16rhYWF2LFjBxo2bAhfX18DRWjaDHm9qtVq7N69G4WFhejQoYOhQjRbte18Y+Fk5iwtLbFz507ExMTAyckJwcHB+Oijj3Dx4kW923rw4AEWL16M8ePHGyFS0zNy5EicOnUKt27dwq1bt/DLL79g5MiRktrSaDSYOnUqgoOD0apVKwNHap5q2/lmiGt148aN2gLswIEDOHLkCOrUqWPEqE2HIa7XP/74A/Xq1YO1tTUmTJiAb7/9Fq+88oqRIq75auv5xsKpFhg0aBDS09Oxb98+hIaGIjExEW3btsXOnTtFt6FQKNC7d2+88sorWLBggdFiNSVubm7o3bs3du7ciR07dqB3795wdXWV1FZkZCQuXbqE3bt3GzhK81Qbzzeg8tfqiBEjcOHCBZw4cQLNmjXDkCFDUFRUZNygTYQhrtfmzZsjJSUFycnJmDhxIkaNGoX//Oc/Roq45qu151t13yuk6jF27FjBz89P1LYKhULo0KGD0L17d+Hx48dGjqz6PXvPf//+/YK/v7/g7+8v/Pjjj4IgCHo/MxEZGSm89NJLwo0bN4wQrWmqzHMTte18q4g+1+qzlEqlULduXSEuLs4IUZkOQ1+vz+revbswfvx4A0Vqmgz1jFNtOd8Egc841VqvvPKKqE93KRQKhISEoE6dOti3bx9sbGyqIDrTERoaiidPnkClUqFnz5567SsIAt5//318++23SEhIQMOGDY0Upfmo7edbWcReq88TBAGCIBjk2caaojLXa1k0Gk2tyl9l1KbzzfyfuKzlHj58iLfeegtjxoxBQEAA7O3tcfbsWaxcuRL9+vUrd9+SP2KPHj3CV199BYVCAYVCAeDpsLiFhUVVdKFaWVhYIDU1VfuzPiIjIxEXF4fvv/8e9vb2yMzMBAA4OjrC1tbW4LGamry8PKSkpOgsq1+//gsfHq3t51tlrtUbN27g66+/RkhICNzc3HD37l0sX74ctra2CAsLq6IeVL/KXK9z5sxBr1694Ofnh/z8fMTFxSExMRGHDh0yRqgmRd9rtbafbyyczFy9evUQFBSEtWvX4q+//oJKpYKvry/GjRuHjz76qNx9z58/j+TkZABAkyZNdNbdvHkT/v7+xgrbpDg4OEjab9OmTQCALl266CzfsWOHqBfy1XSJiYlo06aNzrKxY8di69atZW5f28+3ylyrNjY2+Pnnn7Fu3Trk5OTAw8MDnTt3xunTp+Hu7l5FPTANUq/X+/fv491330VGRgYcHR0REBCAQ4cO4W9/+5uBIzQ9+l6rtf18kwmCIFR3EEREREQ1AZ9xIiIiIhKJhVMtFhsbq30Hx/NTy5Ytqzs8k3b79u0X5q5evXq4fft2dYdocni+ScfcVQ6vV/3wfCsfb9XVYvn5+bh3716Z66ysrNCgQYMqjqjmKC4uRlpa2gvX+/v714q3XeuD55t0zF3l8HrVD8+38rFwIiIiIhKJt+qIiIiIRGLhRERERCQSCyciIiIikVg4EREREYnEwomIiIhIJBZORERERCKxcCIiIiIS6f8BGGh7n2dr6MsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.grid(visible=True, which='major', alpha=0.2, color='#748c9d')\n",
    "\n",
    "\n",
    "x = np.arange(0, 6)\n",
    "y = np.arange(-0.35, 0.15, 0.05)\n",
    "plt.bar(x-0.3, heights_5, width=0.25, label='5-min', color='#072449')\n",
    "plt.bar(x, heights_10, width=0.25, label='10-min', color='#fbd404')\n",
    "plt.bar(x+0.3, heights_15, width=0.25, label='15-min', color='#fc0313')\n",
    "\n",
    "\n",
    "plt.ylabel('Forecast Skill [%]')\n",
    "plt.xticks(ticks=x, labels=['S_2', 'M_2', 'L_2', 'S_3', 'M_3', 'L_3'])\n",
    "plt.yticks(ticks=y, labels=[f'{(item*100):.0f}%' for item in y])\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'img\\DLR\\results_mlps.png', dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
